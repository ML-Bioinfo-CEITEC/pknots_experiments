{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a20dc007-7bd3-4780-a15a-40c868d8c033",
   "metadata": {},
   "source": [
    "# Calculate embeddings from ESM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18beac62-bef4-484a-af8f-4d88889e4f9b",
   "metadata": {},
   "source": [
    "Code taken from here https://github.com/facebookresearch/esm/blob/main/scripts/extract.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca93f1-5d0a-42d1-8fea-1a7eaf589784",
   "metadata": {},
   "source": [
    "### Prepare inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b785d321-2109-43b8-9544-b3bf30273834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac420679-2e26-412d-905d-c6e3d5c4df0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration EvaKlimentova--knots_AF-265fee554925f78a\n",
      "Found cached dataset parquet (/home/jovyan/.cache/huggingface/datasets/EvaKlimentova___parquet/EvaKlimentova--knots_AF-265fee554925f78a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52985b69e0e4decb0040c1dcd0c7406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dss = load_dataset('EvaKlimentova/knots_AF')\n",
    "test = dss['test']\n",
    "train = dss['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54386aba-8abc-45d4-90bd-398cdf8c1e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTA_TRAIN = \"Knots_AF_train.fasta\"\n",
    "OUTPUT_TRAIN = \"Knots_AF_train_embeddings.csv\"\n",
    "FASTA_TEST = \"Knots_AF_test.fasta\"\n",
    "OUTPUT_TEST = \"Knots_AF_test_embeddings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f3d9cad-b11d-4e3f-b18f-7216b505f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train = open(FASTA_TRAIN, 'w')\n",
    "for row in train:\n",
    "    file_train.write(f'>{row[\"ID\"]},{row[\"label\"]}\\n{row[\"uniprotSequence\"]}\\n')\n",
    "\n",
    "file_test = open(FASTA_TEST, 'w')\n",
    "for row in test:\n",
    "    file_test.write(f'>{row[\"ID\"]},{row[\"label\"]}\\n{row[\"uniprotSequence\"]}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e35281-8d53-461d-ab5e-342831e2b68d",
   "metadata": {},
   "source": [
    "## Compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41787e45-72f1-493a-b44f-0a6a92402e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from esm import Alphabet, FastaBatchedDataset, ProteinBertModel, pretrained, MSATransformer\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "def compute_embeddings(inp, output):\n",
    "\n",
    "    # instead of args giving default numbers\n",
    "\n",
    "    include = ['mean']\n",
    "\n",
    "    model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", \"esm2_t36_3B_UR50D\")\n",
    "    model.eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        print(\"Transferred model to GPU\")\n",
    "\n",
    "    dataset = FastaBatchedDataset.from_file(inp)\n",
    "    batches = dataset.get_batch_indices(4096, extra_toks_per_seq=1)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, collate_fn=alphabet.get_batch_converter(1022), batch_sampler=batches\n",
    "    )\n",
    "    print(f\"Read {inp} with {len(dataset)} sequences\")\n",
    "\n",
    "    return_contacts = \"contacts\" in include\n",
    "\n",
    "    assert all(-(model.num_layers + 1) <= i <= model.num_layers for i in [-1])\n",
    "    repr_layers = [(i + model.num_layers + 1) % (model.num_layers + 1) for i in [-1]]\n",
    "\n",
    "    file = open(output, 'w')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (labels, strs, toks) in enumerate(data_loader):\n",
    "            print(\n",
    "                f\"Processing {batch_idx + 1} of {len(batches)} batches ({toks.size(0)} sequences)\"\n",
    "            )\n",
    "            if torch.cuda.is_available():\n",
    "                toks = toks.to(device=\"cuda\", non_blocking=True)\n",
    "\n",
    "            out = model(toks, repr_layers=repr_layers, return_contacts=return_contacts)\n",
    "\n",
    "            logits = out[\"logits\"].to(device=\"cpu\")\n",
    "            representations = {\n",
    "                layer: t.to(device=\"cpu\") for layer, t in out[\"representations\"].items()\n",
    "            }\n",
    "            if return_contacts:\n",
    "                contacts = out[\"contacts\"].to(device=\"cpu\")\n",
    "\n",
    "            for i, label in enumerate(labels):\n",
    "                result = {\"label\": label}\n",
    "                truncate_len = min(1022, len(strs[i]))\n",
    "                # Call clone on tensors to ensure tensors are not views into a larger representation\n",
    "                # See https://github.com/pytorch/pytorch/issues/1995\n",
    "                if \"per_tok\" in include:\n",
    "                    result[\"representations\"] = {\n",
    "                        layer: t[i, 1: truncate_len + 1].clone()\n",
    "                        for layer, t in representations.items()\n",
    "                    }\n",
    "                if \"mean\" in include:\n",
    "                    result[\"mean_representations\"] = {\n",
    "                        layer: t[i, 1: truncate_len + 1].mean(0).clone()\n",
    "                        for layer, t in representations.items()\n",
    "                    }\n",
    "                if \"bos\" in include:\n",
    "                    result[\"bos_representations\"] = {\n",
    "                        layer: t[i, 0].clone() for layer, t in representations.items()\n",
    "                    }\n",
    "                if return_contacts:\n",
    "                    result[\"contacts\"] = contacts[i, : truncate_len, : truncate_len].clone()\n",
    "\n",
    "                #print(result['mean_representations'][36].detach().numpy())\n",
    "                #print(result['label'])\n",
    "\n",
    "                file.write(result['label'] + ',' + ','.join(str(e) for e in result['mean_representations'][36].detach().numpy()))\n",
    "                file.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea4c0ba-716e-4724-a017-07a9ceb32cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred model to GPU\n",
      "Read Knots_AF_test.fasta with 37401 sequences\n",
      "Processing 1 of 3937 batches (48 sequences)\n",
      "Processing 2 of 3937 batches (45 sequences)\n",
      "Processing 3 of 3937 batches (43 sequences)\n",
      "Processing 4 of 3937 batches (41 sequences)\n",
      "Processing 5 of 3937 batches (40 sequences)\n",
      "Processing 6 of 3937 batches (39 sequences)\n",
      "Processing 7 of 3937 batches (37 sequences)\n",
      "Processing 8 of 3937 batches (36 sequences)\n",
      "Processing 9 of 3937 batches (35 sequences)\n",
      "Processing 10 of 3937 batches (35 sequences)\n",
      "Processing 11 of 3937 batches (34 sequences)\n",
      "Processing 12 of 3937 batches (33 sequences)\n",
      "Processing 13 of 3937 batches (32 sequences)\n",
      "Processing 14 of 3937 batches (32 sequences)\n",
      "Processing 15 of 3937 batches (31 sequences)\n",
      "Processing 16 of 3937 batches (31 sequences)\n",
      "Processing 17 of 3937 batches (30 sequences)\n",
      "Processing 18 of 3937 batches (30 sequences)\n",
      "Processing 19 of 3937 batches (30 sequences)\n",
      "Processing 20 of 3937 batches (29 sequences)\n",
      "Processing 21 of 3937 batches (29 sequences)\n",
      "Processing 22 of 3937 batches (29 sequences)\n",
      "Processing 23 of 3937 batches (29 sequences)\n",
      "Processing 24 of 3937 batches (29 sequences)\n",
      "Processing 25 of 3937 batches (29 sequences)\n",
      "Processing 26 of 3937 batches (29 sequences)\n",
      "Processing 27 of 3937 batches (28 sequences)\n",
      "Processing 28 of 3937 batches (28 sequences)\n",
      "Processing 29 of 3937 batches (28 sequences)\n",
      "Processing 30 of 3937 batches (28 sequences)\n",
      "Processing 31 of 3937 batches (28 sequences)\n",
      "Processing 32 of 3937 batches (28 sequences)\n",
      "Processing 33 of 3937 batches (28 sequences)\n",
      "Processing 34 of 3937 batches (28 sequences)\n",
      "Processing 35 of 3937 batches (27 sequences)\n",
      "Processing 36 of 3937 batches (27 sequences)\n",
      "Processing 37 of 3937 batches (27 sequences)\n",
      "Processing 38 of 3937 batches (27 sequences)\n",
      "Processing 39 of 3937 batches (27 sequences)\n",
      "Processing 40 of 3937 batches (27 sequences)\n",
      "Processing 41 of 3937 batches (27 sequences)\n",
      "Processing 42 of 3937 batches (27 sequences)\n",
      "Processing 43 of 3937 batches (27 sequences)\n",
      "Processing 44 of 3937 batches (26 sequences)\n",
      "Processing 45 of 3937 batches (26 sequences)\n",
      "Processing 46 of 3937 batches (26 sequences)\n",
      "Processing 47 of 3937 batches (26 sequences)\n",
      "Processing 48 of 3937 batches (26 sequences)\n",
      "Processing 49 of 3937 batches (26 sequences)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for (inp, out) in [(FASTA_TEST, OUTPUT_TEST), (FASTA_TRAIN, OUTPUT_TRAIN)]:\n",
    "    compute_embeddings(inp, out)\n",
    "    \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a3e26e9-7efb-4a28-8830-77e18901a90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating embedding time:  76031.86687970161\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating embedding time: \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0783bef-c8b6-4c7b-adbb-4403b858a470",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:esmfold]",
   "language": "python",
   "name": "conda-env-esmfold-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
