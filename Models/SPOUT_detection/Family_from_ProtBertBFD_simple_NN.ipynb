{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148d1c28-5750-43fb-9a8c-4e3f4e58c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b148c9-b7b5-4ccd-b820-85b904c5b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 7\n",
    "HIDDEN = 64\n",
    "INPUT = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a3ca787-ed80-4bb7-8b34-66bf132c27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, inp, hidden, output, device):\n",
    "        super(Network,self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.linear1=nn.Linear(inp, hidden)\n",
    "        self.linear2=nn.Linear(hidden, output)\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    " \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.linear1(x)\n",
    "        x=self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    def train_model(self, dataset, epochs):  \n",
    "        self.train()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001) # TODO tune\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            with tqdm(dataset, unit=\"batch\") as tepoch:\n",
    "                for inputs, targets in tepoch:\n",
    "\n",
    "                    inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                    tepoch.set_description(f\"Epoch {epoch + 1}\")\n",
    "                    \n",
    "                    targets = targets[:, 0].long() # TODO what is that?\n",
    "\n",
    "                    # clear the gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    # compute the model output\n",
    "                    yhat = self(inputs)\n",
    "                    # calculate accuracy\n",
    "                    correct = (yhat.argmax(1) == targets).type(torch.float).sum().item()\n",
    "                    accuracy = correct / len(inputs)\n",
    "                    # calculate loss\n",
    "                    loss = self.loss(yhat, targets)\n",
    "                    # credit assignment\n",
    "                    loss.backward()\n",
    "                    # update model weights\n",
    "                    optimizer.step()\n",
    "\n",
    "                    tepoch.set_postfix(loss=loss.item(), accuracy=100. * accuracy)\n",
    "        \n",
    "    def test(self, dataloader):\n",
    "        self.eval()\n",
    "        pred_label, actuals = list(), list()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in dataloader:\n",
    "                targets = targets[:, 0].long()\n",
    "                \n",
    "                inputs = inputs.to(self.device)\n",
    "                \n",
    "                # evaluate the model on the test set\n",
    "                yhat = self(inputs)\n",
    "                yhat = yhat.cpu().detach().numpy()\n",
    "                actual = targets.numpy()\n",
    "                yhat = yhat.argmax(1)\n",
    "                # reshape for stacking\n",
    "                actual = actual.reshape((len(actual), 1))\n",
    "                yhat = yhat.reshape((len(yhat), 1))\n",
    "                # store\n",
    "                pred_label.append(yhat)\n",
    "                actuals.append(actual)\n",
    "        pred_label, actuals = np.vstack(pred_label), np.vstack(actuals)\n",
    "        print(\"Predictions: \", pred_label[:10])\n",
    "        print(\"Real labels: \", actuals[:10])\n",
    "        # calculate accuracy\n",
    "        acc = metrics.accuracy_score(actuals, pred_label)\n",
    "        f1 = metrics.f1_score(actuals, pred_label, average='micro', zero_division=0)\n",
    "        print(f\"Test metrics: \\n Accuracy: {acc}, F1 score: {float(f1):>6f}\\n\")\n",
    "        return acc, f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96bdf9ff-cb4d-42d6-9d04-9d11949526c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.X = np.float32(df.drop(columns=['Family']))\n",
    "        self.y = np.expand_dims(df['Family'].to_numpy(), axis=1)\n",
    "        self.len = len(df)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e3cd501-af5b-4d27-9e15-73cd136fc7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_mapping(family):\n",
    "    if family == 'SPOUT':\n",
    "        return 0\n",
    "    elif family == 'AdoMet synthase':\n",
    "        return 1\n",
    "    elif family == 'Carbonic anhydrase':\n",
    "        return 2\n",
    "    elif family == 'ATCase/OTCase':\n",
    "        return 3\n",
    "    elif family == 'membrane':\n",
    "        return 4\n",
    "    elif family == 'VIT':\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "def prepare_AF_dataset(path, type):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    \n",
    "    dss = load_dataset('EvaKlimentova/knots_AF')\n",
    "    hf = pd.DataFrame(dss[type])\n",
    "    hf = hf.drop(columns=['uniprotSequence', 'label', 'latestVersion', 'globalMetricValue', 'uniprotStart', 'uniprotEnd', 'Length', 'Domain_architecture', 'InterPro', 'Max_Topology', 'Max Freq', 'Knot Core'])\n",
    "    df_family = pd.merge(hf, df, on=\"ID\")\n",
    "    \n",
    "    # delete unknotted SPOUTs\n",
    "    df_family = df_family.drop(df_family[(df_family['FamilyName'] == 'SPOUT') & (df_family['label'] == 0)].index)\n",
    "    \n",
    "    # sort proteins into a couple of family bins\n",
    "    df_family['Family'] = df_family['FamilyName'].apply(family_mapping)    \n",
    "    \n",
    "    df_family = df_family.drop(columns=['ID', 'label', 'FamilyName'])\n",
    "    return df_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cfa9454-c841-4c61-8935-dc825c4097ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration EvaKlimentova--knots_AF-293560de9ceccb3f\n",
      "Found cached dataset parquet (/home/jovyan/.cache/huggingface/datasets/EvaKlimentova___parquet/EvaKlimentova--knots_AF-293560de9ceccb3f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b8feb6d65b453e840863ad45ba792b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration EvaKlimentova--knots_AF-293560de9ceccb3f\n",
      "Found cached dataset parquet (/home/jovyan/.cache/huggingface/datasets/EvaKlimentova___parquet/EvaKlimentova--knots_AF-293560de9ceccb3f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a918c89adbbb4b13937b607117096748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = prepare_AF_dataset(\"../Alphafold_dataset/ProtBertBFD_train_embedding_af_v3.csv\", 'train')\n",
    "test_df = prepare_AF_dataset(\"../Alphafold_dataset/ProtBertBFD_test_embedding_af_v3.csv\", 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c6f4cf6-cb68-426c-86a0-94382e0b790a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 155624\n",
      "         f0        f1        f2        f3        f4        f5        f6  \\\n",
      "0  0.026727 -0.032709 -0.027460  0.023039  0.018919  0.020549  0.009272   \n",
      "1 -0.006818 -0.011500 -0.000443 -0.002459 -0.000295  0.000784 -0.004652   \n",
      "2  0.014304 -0.017095 -0.003410  0.000148  0.022026  0.002258  0.015533   \n",
      "3  0.005448 -0.001238  0.002784  0.006303  0.003013  0.010680 -0.014094   \n",
      "4  0.007396  0.012624  0.000298  0.007900  0.010098  0.012833 -0.004366   \n",
      "\n",
      "         f7        f8        f9  ...     f1015     f1016     f1017     f1018  \\\n",
      "0 -0.005804 -0.021650  0.027531  ... -0.043956 -0.042798  0.006104 -0.021828   \n",
      "1  0.005460 -0.007820  0.005914  ... -0.016875  0.004226  0.005704 -0.005163   \n",
      "2  0.006351 -0.022573  0.021902  ... -0.011653 -0.021954 -0.009635  0.029997   \n",
      "3 -0.006538 -0.005705 -0.002041  ... -0.008526 -0.009459  0.004119 -0.001539   \n",
      "4  0.011860 -0.006266 -0.001095  ... -0.023012 -0.002771  0.008065  0.001363   \n",
      "\n",
      "      f1019     f1020     f1021     f1022     f1023  Family  \n",
      "0 -0.011685 -0.015414 -0.007688 -0.001579  0.015265       5  \n",
      "1  0.002065  0.001777 -0.001766 -0.006042 -0.001147       1  \n",
      "2  0.017102 -0.022601 -0.003827 -0.000879  0.005272       5  \n",
      "3 -0.013712  0.012866 -0.001556 -0.006389  0.003397       0  \n",
      "4 -0.011313 -0.004297 -0.010823 -0.011609  0.002771       5  \n",
      "\n",
      "[5 rows x 1025 columns]\n",
      "Test dataset size: 38862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset size: {len(train_df)}\")\n",
    "print(train_df.head(5))\n",
    "print(f\"Test dataset size: {len(test_df)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd5c6c32-5345-4a47-bf37-612db7a0af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = EmbeddingDataset(train_df)\n",
    "train_loader = DataLoader(train_dset, batch_size=32, shuffle=True)\n",
    "test_dset = EmbeddingDataset(test_df)\n",
    "test_loader = DataLoader(test_dset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff6d464e-cae5-4b72-946b-65d87cfaa247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Run on GPU or CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7311b4b2-2f0e-4b33-ac7c-c856ff68158f",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b339e12f-b2aa-42a5-a082-ca7f7211c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(INPUT, HIDDEN, N_CLASSES, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3efe0e0d-2291-432d-b83c-653e811145cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (linear1): Linear(in_features=1024, out_features=64, bias=True)\n",
      "  (linear2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  (loss): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dbae39f-8967-4f8c-a741-8d69387315f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dset.X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf02dc23-eb28-4bd3-9149-9a0a69e58475",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 4864/4864 [00:15<00:00, 304.94batch/s, accuracy=100, loss=0.261] \n",
      "Epoch 2: 100%|██████████| 4864/4864 [00:18<00:00, 263.95batch/s, accuracy=100, loss=0.0177] \n",
      "Epoch 3: 100%|██████████| 4864/4864 [00:18<00:00, 269.90batch/s, accuracy=87.5, loss=0.19]  \n",
      "Epoch 8:  53%|█████▎    | 2577/4864 [00:11<00:10, 222.91batch/s, accuracy=100, loss=0.00884] IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 8: 100%|██████████| 4864/4864 [00:19<00:00, 247.56batch/s, accuracy=100, loss=0.00329] \n",
      "Epoch 9:   7%|▋         | 338/4864 [00:01<00:18, 241.77batch/s, accuracy=100, loss=0.0122]  IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 10:  38%|███▊      | 1851/4864 [00:05<00:12, 242.51batch/s, accuracy=100, loss=0.00451] IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 10:  92%|█████████▏| 4466/4864 [00:15<00:01, 226.01batch/s, accuracy=96.9, loss=0.135]  IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train_model(train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e9f5064-4751-4fc4-9897-bf5eb46e5b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [[5]\n",
      " [0]\n",
      " [0]\n",
      " [5]\n",
      " [0]\n",
      " [4]\n",
      " [0]\n",
      " [5]\n",
      " [5]\n",
      " [0]]\n",
      "Real labels:  [[5]\n",
      " [0]\n",
      " [0]\n",
      " [5]\n",
      " [0]\n",
      " [4]\n",
      " [0]\n",
      " [5]\n",
      " [5]\n",
      " [0]]\n",
      "Test metrics: \n",
      " Accuracy: 0.9945447995471154, F1 score: 0.994545\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9945447995471154, 0.9945447995471154)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb89471d-947f-467e-a145-8de670e64e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"ProtBertBFD_embedding_CNN_family.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e81661-d3dc-47bb-b78b-abc0359b712b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers]",
   "language": "python",
   "name": "conda-env-transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
