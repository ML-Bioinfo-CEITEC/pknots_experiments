{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SBhmsvbdrS9"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MFO7oytsYB_L"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dropout, GlobalAveragePooling1D, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "i4RWxGBL3QU7"
   },
   "outputs": [],
   "source": [
    "df_neg = pd.read_csv(\"Rossmann_unknotted.csv\")[[\"seq\"]]\n",
    "df_neg[\"label\"] = 0\n",
    "\n",
    "df_pos = pd.read_csv(\"SPOUT_knotted.csv\", sep=';')[[\"seq\"]]\n",
    "df_pos[\"label\"] = 1\n",
    "df_pos\n",
    "\n",
    "df_merged = pd.concat([df_neg, df_pos], ignore_index=True, sort=False).sample(frac=0.5, random_state=42).rename(columns={\"seq\": \"sequence\", \"label\": \"label\"})\n",
    "# delete long sequences\n",
    "df_merged = df_merged[df_merged['sequence'].str.len() <= 500]\n",
    "# padd shorter sequences\n",
    "df_merged['sequence'] = df_merged['sequence'].apply(lambda x: x + (500 - len(x))*'X')\n",
    "\n",
    "df_train, df_test = train_test_split(df_merged, test_size=0.2, random_state=42)\n",
    "del(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MSUVeyHtYb6C"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 12:27:45.916766: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-27 12:27:47.119778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 41249 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:27:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "nucleo_dic = {\n",
    "    \"A\": 0,\n",
    "    \"R\": 1,\n",
    "    \"N\": 2,\n",
    "    \"D\": 3,\n",
    "    \"C\": 4,\n",
    "    \"Q\": 5,\n",
    "    \"E\": 6,\n",
    "    \"G\": 7,\n",
    "    \"H\": 8,\n",
    "    \"I\": 9,\n",
    "    \"L\": 10,\n",
    "    \"K\": 11,\n",
    "    \"M\": 12,\n",
    "    \"F\": 13,\n",
    "    \"P\": 14,\n",
    "    \"S\": 15,\n",
    "    \"T\": 16,\n",
    "    \"W\": 17,\n",
    "    \"Y\": 18,\n",
    "    \"V\": 19,\n",
    "    \"X\": 20\n",
    "}\n",
    "\n",
    "\n",
    "dataset_train = df_train['sequence'].tolist()\n",
    "labels_train = np.array(df_train['label'])\n",
    "# numericalize using the dictionary\n",
    "dataset_ordinal_train = [[nucleo_dic[letter] for letter in sequence] for sequence in dataset_train]\n",
    "# translate number values to one-hot vectors\n",
    "dataset_onehot_train = tf.one_hot(dataset_ordinal_train, depth=21)\n",
    "del(dataset_ordinal_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "d6NicFJVY2h2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test = df_test['sequence'].tolist()\n",
    "labels_test = np.array(df_test['label'])\n",
    "# we use the same nucleo_dic as on the example before\n",
    "dataset_ordinal_test = [[nucleo_dic[letter] for letter in sequence] for sequence in dataset_test]\n",
    "dataset_onehot_test = tf.one_hot(dataset_ordinal_test, depth=21)\n",
    "del(dataset_ordinal_test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsCkvaT_dxDa"
   },
   "source": [
    "## Model\n",
    "\n",
    "We have adapted model from our original [paper](https://www.frontiersin.org/articles/10.3389/fgene.2020.568546/full). Note it is sligtly more complex model than what we have seen yesterday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3hQFWf3uZWG6"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Conv1D(32, kernel_size=8, data_format='channels_last', activation='relu', input_shape=(500,21)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(),\n",
    "        Conv1D(16, kernel_size=8, data_format='channels_last', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(),\n",
    "        Conv1D(4, kernel_size=8, data_format='channels_last', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(),\n",
    "        Dropout(0.3),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "YROigDsQZ8Pd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 493, 32)           5408      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 493, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 246, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 239, 16)           4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 239, 16)           64        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 119, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 112, 4)            516       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 112, 4)            16        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 56, 4)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 56, 4)             0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 10,249\n",
      "Trainable params: 10,145\n",
      "Non-trainable params: 104\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-JO2cahgodo"
   },
   "source": [
    "## Training and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2o83ueDZv59",
    "outputId": "a4f7d470-5152-4971-9670-eb0363d39835"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 12:26:13.703856: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 12:26:15.301247: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2022-10-27 12:26:16.771563: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-27 12:26:16.772391: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-27 12:26:16.772410: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2022-10-27 12:26:16.772797: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-27 12:26:16.772851: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-10-27 12:26:18.308191: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496/496 [==============================] - 9s 7ms/step - loss: 0.5319 - accuracy: 0.7460 - val_loss: 2.6287 - val_accuracy: 0.4033\n",
      "Epoch 2/10\n",
      "496/496 [==============================] - 2s 4ms/step - loss: 0.2425 - accuracy: 0.9174 - val_loss: 0.3722 - val_accuracy: 0.9063\n",
      "Epoch 3/10\n",
      "496/496 [==============================] - 2s 4ms/step - loss: 0.1096 - accuracy: 0.9674 - val_loss: 0.0925 - val_accuracy: 0.9733\n",
      "Epoch 4/10\n",
      "496/496 [==============================] - 2s 4ms/step - loss: 0.0908 - accuracy: 0.9770 - val_loss: 0.0823 - val_accuracy: 0.9794\n",
      "Epoch 5/10\n",
      "496/496 [==============================] - 2s 4ms/step - loss: 0.1092 - accuracy: 0.9708 - val_loss: 0.0667 - val_accuracy: 0.9804\n",
      "Epoch 6/10\n",
      "496/496 [==============================] - 2s 4ms/step - loss: 0.0538 - accuracy: 0.9862 - val_loss: 0.0425 - val_accuracy: 0.9897\n",
      "Epoch 7/10\n",
      "496/496 [==============================] - 2s 4ms/step - loss: 0.0349 - accuracy: 0.9909 - val_loss: 0.0329 - val_accuracy: 0.9921\n",
      "Epoch 8/10\n",
      "496/496 [==============================] - 2s 4ms/step - loss: 0.0709 - accuracy: 0.9865 - val_loss: 0.1552 - val_accuracy: 0.9660\n",
      "Epoch 9/10\n",
      "496/496 [==============================] - 2s 4ms/step - loss: 0.0275 - accuracy: 0.9931 - val_loss: 0.0230 - val_accuracy: 0.9945\n",
      "Epoch 10/10\n",
      "496/496 [==============================] - 2s 4ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.0204 - val_accuracy: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0a92f321f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    dataset_onehot_train,\n",
    "    labels_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    validation_split=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bncLlx3PZ7GJ"
   },
   "outputs": [],
   "source": [
    "model.save(\"cnn_10epochs.h5\", save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "aJdOi11WhIhC"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('cnn_10epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.026554161682724953\n",
      "Test accuracy: 0.9947946667671204\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(dataset_onehot_test, labels_test, verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
