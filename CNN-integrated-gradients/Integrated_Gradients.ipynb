{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MFO7oytsYB_L"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dropout, GlobalAveragePooling1D, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MSUVeyHtYb6C"
      },
      "outputs": [],
      "source": [
        "nucleo_dic = {\n",
        "    \"A\": 0,\n",
        "    \"R\": 1,\n",
        "    \"N\": 2,\n",
        "    \"D\": 3,\n",
        "    \"C\": 4,\n",
        "    \"Q\": 5,\n",
        "    \"E\": 6,\n",
        "    \"G\": 7,\n",
        "    \"H\": 8,\n",
        "    \"I\": 9,\n",
        "    \"L\": 10,\n",
        "    \"K\": 11,\n",
        "    \"M\": 12,\n",
        "    \"F\": 13,\n",
        "    \"P\": 14,\n",
        "    \"S\": 15,\n",
        "    \"T\": 16,\n",
        "    \"W\": 17,\n",
        "    \"Y\": 18,\n",
        "    \"V\": 19,\n",
        "    \"X\": 20\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKGAWOn1uQfv",
        "outputId": "2b6a6e0f-edaa-434c-9c12-1e0c88346448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: 'git lfs clone' is deprecated and will not be updated\n",
            "          with new flags from 'git clone'\n",
            "\n",
            "'git clone' has been updated in upstream Git to have comparable\n",
            "speeds to 'git lfs clone'.\n",
            "Cloning into 'knots_simple_CNN'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n",
            "Git LFS: (1 of 1 files) 187.61 KB / 187.61 KB\n"
          ]
        }
      ],
      "source": [
        "!git lfs clone https://huggingface.co/EvaKlimentova/knots_simple_CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aJdOi11WhIhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab361323-9fcb-41e1-a642-bbc3a22fecb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 493, 32)           5408      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 493, 32)          128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 246, 32)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 239, 16)           4112      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 239, 16)          64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 119, 16)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 112, 4)            516       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 112, 4)           16        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 56, 4)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 56, 4)             0         \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 4)                0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,249\n",
            "Trainable params: 10,145\n",
            "Non-trainable params: 104\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model('knots_simple_CNN/cnn_10epochs.h5')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbKn2pf5mgcw"
      },
      "source": [
        "## Integrated Gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DbphLAYIminT"
      },
      "outputs": [],
      "source": [
        "def generate_alphas(m_steps=50, method='riemann_trapezoidal'):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    m_steps(Tensor): A 0D tensor of an int corresponding to the number of linear\n",
        "    interpolation steps for computing an approximate integral. Default is 50.\n",
        "    method(str): A string representing the integral approximation method. The\n",
        "       following methods are implemented:\n",
        "      - riemann_trapezoidal(default)\n",
        "      - riemann_left\n",
        "      - riemann_midpoint\n",
        "      - riemann_right\n",
        "    Returns:\n",
        "      alphas(Tensor): A 1D tensor of uniformly spaced floats with the shape\n",
        "      (m_steps,).\n",
        "      \"\"\"\n",
        "    m_steps_float = tf.cast(m_steps, float)\n",
        "\n",
        "    if method == 'riemann_trapezoidal':\n",
        "        alphas = tf.linspace(0.0, 1.0, m_steps+1)\n",
        "    elif method == 'riemann_left':\n",
        "        alphas = tf.linspace(0.0, 1.0 - (1.0 / m_steps_float), m_steps)\n",
        "    elif method == 'riemann_midpoint':\n",
        "        alphas = tf.linspace(1.0 / (2.0 * m_steps_float), 1.0 - 1.0 / (2.0 * m_steps_float), m_steps)\n",
        "    elif method == 'riemann_right':\n",
        "        alphas = tf.linspace(1.0 / m_steps_float, 1.0, m_steps)\n",
        "    else:\n",
        "        raise AssertionError(\"Provided Riemann approximation method is not valid.\")\n",
        "\n",
        "    return alphas\n",
        "\n",
        "def generate_path_inputs(baseline, input, alphas):\n",
        "    \"\"\"\n",
        "    Generate interpolated 'images' along a linear path at alpha intervals between a baseline tensor\n",
        "\n",
        "    baseline: 2D, shape: (200, 4)\n",
        "    input: preprocessed sample, shape: (200, 4)\n",
        "    alphas: list of steps in interpolated image ,shape: (21)\n",
        "\n",
        "\n",
        "    return: shape (21, 200, 4)\n",
        "    \"\"\"\n",
        "    # Expand dimensions for vectorized computation of interpolations.\n",
        "    alphas_x = alphas[:, tf.newaxis, tf.newaxis]\n",
        "    baseline_x = tf.expand_dims(baseline, axis=0)\n",
        "    input_x = tf.expand_dims(input, axis=0)\n",
        "    delta = input_x - baseline_x\n",
        "    path_inputs = baseline_x + alphas_x * delta\n",
        "\n",
        "    return path_inputs\n",
        "\n",
        "def compute_gradients(model, path_inputs):\n",
        "    \"\"\"\n",
        "    compute dependency of each field on whole result, compared to interpolated 'images'\n",
        "\n",
        "    :param model: trained model\n",
        "    :param path_inputs: interpolated tensors, shape: (21, 200, 4)\n",
        "    :return: shape: (21, 200, 4)\n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(path_inputs)\n",
        "        predictions = model(path_inputs)\n",
        "\n",
        "        outputs = []\n",
        "        for envelope in predictions:\n",
        "            outputs.append(envelope[0])\n",
        "        outputs = tf.convert_to_tensor(outputs, dtype=tf.float32)\n",
        "\n",
        "    gradients = tape.gradient(outputs, path_inputs)\n",
        "    return gradients\n",
        "\n",
        "def integral_approximation(gradients, method='riemann_trapezoidal'):\n",
        "    \"\"\"Compute numerical approximation of integral from gradients.\n",
        "    Args:\n",
        "    gradients(Tensor): A 4D tensor of floats with the shape\n",
        "    (m_steps, img_height, img_width, 3).\n",
        "    method(str): A string representing the integral approximation method. The\n",
        "    following methods are implemented:\n",
        "    - riemann_trapezoidal(default)\n",
        "    - riemann_left\n",
        "    - riemann_midpoint\n",
        "    - riemann_right\n",
        "    Returns:\n",
        "    integrated_gradients(Tensor): A 3D tensor of floats with the shape\n",
        "    (img_height, img_width, 3).\n",
        "    \"\"\"\n",
        "    if method == 'riemann_trapezoidal':\n",
        "        grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n",
        "    elif method == 'riemann_left':\n",
        "        grads = gradients\n",
        "    elif method == 'riemann_midpoint':\n",
        "        grads = gradients\n",
        "    elif method == 'riemann_right':\n",
        "        grads = gradients\n",
        "    else:\n",
        "        raise AssertionError(\"Provided Riemann approximation method is not valid.\")\n",
        "\n",
        "    # Average integration approximation.\n",
        "    integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n",
        "\n",
        "    return integrated_gradients\n",
        "\n",
        "def integrated_gradients(model, baseline, input, m_steps=50, method='riemann_trapezoidal',\n",
        "                         batch_size=32):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      model(keras.Model): A trained model to generate predictions and inspect.\n",
        "      baseline(Tensor): 2D, shape: (200, 4)\n",
        "      input(Tensor): preprocessed sample, shape: (200, 4)\n",
        "      m_steps(Tensor): A 0D tensor of an integer corresponding to the number of\n",
        "        linear interpolation steps for computing an approximate integral.\n",
        "      method(str): A string representing the integral approximation method. The\n",
        "        following methods are implemented:\n",
        "        - riemann_trapezoidal(default)\n",
        "        - riemann_left\n",
        "        - riemann_midpoint\n",
        "        - riemann_right\n",
        "      batch_size(Tensor): A 0D tensor of an integer corresponding to a batch\n",
        "        size for alpha to scale computation and prevent OOM errors. Note: needs to\n",
        "        be tf.int64 and shoud be < m_steps. Default value is 32.\n",
        "    Returns:\n",
        "      integrated_gradients(Tensor): A 2D tensor of floats with the same\n",
        "        shape as the input tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Generate alphas.\n",
        "    alphas = generate_alphas(m_steps=m_steps,\n",
        "                             method=method)\n",
        "\n",
        "    # Initialize TensorArray outside loop to collect gradients. Note: this data structure\n",
        "    gradient_batches = tf.TensorArray(tf.float32, size=m_steps + 1)\n",
        "\n",
        "    # Iterate alphas range and batch computation for speed, memory efficiency, and scaling to larger m_steps.\n",
        "    for alpha in tf.range(0, len(alphas), batch_size):\n",
        "        from_ = alpha\n",
        "        to = tf.minimum(from_ + batch_size, len(alphas))\n",
        "        alpha_batch = alphas[from_:to]\n",
        "\n",
        "        # 2. Generate interpolated inputs between baseline and input.\n",
        "        interpolated_path_input_batch = generate_path_inputs(baseline=baseline,\n",
        "                                                             input=input,\n",
        "                                                             alphas=alpha_batch)\n",
        "\n",
        "        # 3. Compute gradients between model outputs and interpolated inputs.\n",
        "        gradient_batch = compute_gradients(model=model,\n",
        "                                           path_inputs=interpolated_path_input_batch)\n",
        "\n",
        "        # Write batch indices and gradients to TensorArray.\n",
        "        gradient_batches = gradient_batches.scatter(tf.range(from_, to), gradient_batch)\n",
        "\n",
        "    # Stack path gradients together row-wise into single tensor.\n",
        "    total_gradients = gradient_batches.stack()\n",
        "\n",
        "    # 4. Integral approximation through averaging gradients.\n",
        "    avg_gradients = integral_approximation(gradients=total_gradients,\n",
        "                                           method=method)\n",
        "\n",
        "    # 5. Scale integrated gradients with respect to input.\n",
        "    integrated_gradients = (input - baseline) * avg_gradients\n",
        "\n",
        "    return integrated_gradients\n",
        "\n",
        "def choose_validation_points(integrated_gradients):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "          integrated_gradients(Tensor): A 2D tensor of floats with shape (200, 4).\n",
        "    Return: List of attributes for highlighting DNA string sequence\n",
        "    \"\"\"\n",
        "    attr = np.zeros(500)\n",
        "    for i in range(500):\n",
        "        for j in range(21):\n",
        "            if integrated_gradients[i][j].numpy() == 0:\n",
        "                continue\n",
        "            attr[i] = integrated_gradients[i][j].numpy()\n",
        "    return attr\n",
        "\n",
        "def visualize_token_attrs(sequence, attrs):\n",
        "    \"\"\"\n",
        "    Visualize attributions for given set of tokens.\n",
        "    Args:\n",
        "    - tokens: An array of tokens\n",
        "    - attrs: An array of attributions, of same size as 'tokens',\n",
        "      with attrs[i] being the attribution to tokens[i]\n",
        "\n",
        "    Returns:\n",
        "    - visualization: HTML text with colorful representation of DNA sequence\n",
        "        build on model prediction\n",
        "    \"\"\"\n",
        "\n",
        "    def get_color(attr):\n",
        "        if attr > 0:\n",
        "            red = int(128 * attr) + 127\n",
        "            green = 128 - int(64 * attr)\n",
        "            blue = 128 - int(64 * attr)\n",
        "        else:\n",
        "            red = 128 + int(64 * attr)\n",
        "            green = 128 + int(64 * attr)\n",
        "            blue = int(-128 * attr) + 127\n",
        "\n",
        "        return red, green, blue\n",
        "\n",
        "    # normalize attributions for visualization.\n",
        "    bound = max(abs(max(attrs)), abs(min(attrs)))\n",
        "    attrs = attrs / bound\n",
        "    html_text = \"\"\n",
        "    for i, tok in enumerate(sequence):\n",
        "        r, g, b = get_color(attrs[i])\n",
        "        if abs(attrs[i]) > 0.5:\n",
        "          html_text += \" <span style='color:rgb(%d,%d,%d);font-weight:bold'>%s</span>\" % (r, g, b, tok)\n",
        "        else: \n",
        "          html_text += \" <span style='color:rgb(%d,%d,%d)'>%s</span>\" % (r, g, b, tok)\n",
        "\n",
        "    return html_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SBhmsvbdrS9"
      },
      "source": [
        "## Input your sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ec-Fg1lPuQf1"
      },
      "outputs": [],
      "source": [
        "# HERE\n",
        "seq = 'MKFIVKTQRGMESVAANYIREAISDASVWASPMGYSGLIIVETSDENAGEKILEIPEVERLIPVIAEVPAELEAIVTTAEKIAPLISENETFAVKTKRRGKHGFTSMDVNRELGARIRELTNADVNLSWPDRVVQVEIIGDKAYISVVPGEEFRKFTPDKIDARKLFRKVTLVQMPYWGNHKACRSFGEKIGRAAQAFEVKELIIAPKEKMDAFELAEFIKGVKIGQESRHQIQREAYPWKVEKVPVSVWDLYQVVRDKRRGKRLLIITDPKGPTLAEVKDRLAKDMFYAKEVVIFVGSREGIPRGLFRFADYVVDLAPYMTFATEHGIPAALVSLWEVYEEYARKREKKT'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qksmbvWhuQf1",
        "outputId": "2591604b-90cc-4a6b-96dd-8bac44dfbfb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MKFIVKTQRGMESVAANYIREAISDASVWASPMGYSGLIIVETSDENAGEKILEIPEVERLIPVIAEVPAELEAIVTTAEKIAPLISENETFAVKTKRRGKHGFTSMDVNRELGARIRELTNADVNLSWPDRVVQVEIIGDKAYISVVPGEEFRKFTPDKIDARKLFRKVTLVQMPYWGNHKACRSFGEKIGRAAQAFEVKELIIAPKEKMDAFELAEFIKGVKIGQESRHQIQREAYPWKVEKVPVSVWDLYQVVRDKRRGKRLLIITDPKGPTLAEVKDRLAKDMFYAKEVVIFVGSREGIPRGLFRFADYVVDLAPYMTFATEHGIPAALVSLWEVYEEYARKREKKTXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n"
          ]
        }
      ],
      "source": [
        "if len(seq) > 500:\n",
        "    seq = seq[:500]\n",
        "else:\n",
        "    seq = seq + (500 - len(seq))*'X'\n",
        "    \n",
        "print(seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SljAsEIquQf2"
      },
      "source": [
        "-------------------------------------------------------------------------------------\n",
        "## or try out one of the prepared sequences:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNW8PmvPuQf2"
      },
      "source": [
        "### Positive sequence example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qrhuy5_suQf3"
      },
      "outputs": [],
      "source": [
        "seq = 'MAQQEWLFGLHALQAVLEREPERILELMVLKGRTDERLGEIINQARRFGVSVQFCHRKVLDEKVGGSQHQGVVARAKPARALDENDLAVIVERADKPFLLVLDGVTDPHNLGACLRTADAAGVDAVIVPKDKSASLSGTVSKVACGAAETMPLVQVTNLARTLKTLQEAGVWIIGTAGETTQTLYDTRLDGPMALVMGAEGKGMRRLTRETCDELVKLPMAGSVSSLNVSVATGVCLYEVVRQRQQXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HWeUESYuQf3"
      },
      "source": [
        "### Negative sequence example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OWZk0dSuQf3"
      },
      "outputs": [],
      "source": [
        "seq = 'MAYTVVWFKRDLRVHDHAPLAHAAAHGPVLCLYVLEPSLWAQPDSALQHYQFLRESLRDLAQQLRSCGARLQLAVGETPEVLARLYALQPFARLVSHEETGNGATYARDLAVARWCRRQGVAWQEWPQHGVVRRLPSREQWHGLWQAHMQAPCLPPPLPASLRSVCLPWRDTWPAPETMGLSDAHDPPQRQRGGRAPGQQVLHDFLHARAAFYRGGISSPLTAPTACSRLSPYLALGCLGMREAVQATQQRQVQLKLQDAQQAAHVRQAFLAQFGQHGGGGDVGVPLRTALMRRVREDGRRYAVNLVIGQRVIAAQRGGAGSETGCELHGLSPDEKGLLFKPHTGFLDSEPSLSAVLCGWHEEPGWPCCHRLSXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCbOuC4auQf3"
      },
      "source": [
        "-------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlkegTxYn36E",
        "outputId": "bcb1548a-1f9f-4749-d1d5-df0b0bf23df8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([500, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "seq_onehot = tf.one_hot([nucleo_dic[c] for c in seq], depth=21)\n",
        "\n",
        "seq_onehot.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "DcEBQDxlokr0",
        "outputId": "2e513bf2-0194-40d5-d7f3-242a942e8522"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " <span style='color:rgb(128,128,127)'>M</span> <span style='color:rgb(127,128,128)'>K</span> <span style='color:rgb(128,128,128)'>F</span> <span style='color:rgb(128,128,127)'>I</span> <span style='color:rgb(128,128,127)'>V</span> <span style='color:rgb(128,128,127)'>K</span> <span style='color:rgb(127,128,128)'>T</span> <span style='color:rgb(125,125,134)'>Q</span> <span style='color:rgb(124,124,135)'>R</span> <span style='color:rgb(127,127,129)'>G</span> <span style='color:rgb(127,127,129)'>M</span> <span style='color:rgb(126,126,132)'>E</span> <span style='color:rgb(125,125,133)'>S</span> <span style='color:rgb(127,128,128)'>V</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(125,125,133)'>A</span> <span style='color:rgb(126,126,131)'>N</span> <span style='color:rgb(123,123,138)'>Y</span> <span style='color:rgb(127,127,129)'>I</span> <span style='color:rgb(117,117,149)'>R</span> <span style='color:rgb(115,115,153)'>E</span> <span style='color:rgb(115,115,154)'>A</span> <span style='color:rgb(121,121,142)'>I</span> <span style='color:rgb(119,119,145)'>S</span> <span style='color:rgb(111,111,162)'>D</span> <span style='color:rgb(105,105,174)'>A</span> <span style='color:rgb(117,117,150)'>S</span> <span style='color:rgb(120,120,144)'>V</span> <span style='color:rgb(100,100,184)'>W</span> <span style='color:rgb(128,128,128)'>A</span> <span style='color:rgb(142,121,121)'>S</span> <span style='color:rgb(120,120,143)'>P</span> <span style='color:rgb(155,114,114)'>M</span> <span style='color:rgb(111,111,162)'>G</span> <span style='color:rgb(103,103,177)'>Y</span> <span style='color:rgb(96,96,192);font-weight:bold'>S</span> <span style='color:rgb(92,92,199);font-weight:bold'>G</span> <span style='color:rgb(127,128,128)'>L</span> <span style='color:rgb(96,96,191);font-weight:bold'>I</span> <span style='color:rgb(152,116,116)'>I</span> <span style='color:rgb(111,111,161)'>V</span> <span style='color:rgb(93,93,197);font-weight:bold'>E</span> <span style='color:rgb(127,127,129)'>T</span> <span style='color:rgb(110,110,164)'>S</span> <span style='color:rgb(107,107,169)'>D</span> <span style='color:rgb(98,98,188)'>E</span> <span style='color:rgb(127,127,130)'>N</span> <span style='color:rgb(100,100,184)'>A</span> <span style='color:rgb(125,125,133)'>G</span> <span style='color:rgb(101,101,181)'>E</span> <span style='color:rgb(111,111,161)'>K</span> <span style='color:rgb(154,115,115)'>I</span> <span style='color:rgb(172,106,106)'>L</span> <span style='color:rgb(69,69,245);font-weight:bold'>E</span> <span style='color:rgb(107,107,169)'>I</span> <span style='color:rgb(108,108,168)'>P</span> <span style='color:rgb(116,116,151)'>E</span> <span style='color:rgb(116,116,152)'>V</span> <span style='color:rgb(99,99,185)'>E</span> <span style='color:rgb(95,95,194);font-weight:bold'>R</span> <span style='color:rgb(124,124,136)'>L</span> <span style='color:rgb(128,128,128)'>I</span> <span style='color:rgb(95,95,193);font-weight:bold'>P</span> <span style='color:rgb(111,111,161)'>V</span> <span style='color:rgb(111,111,161)'>I</span> <span style='color:rgb(103,103,177)'>A</span> <span style='color:rgb(99,99,186)'>E</span> <span style='color:rgb(121,121,141)'>V</span> <span style='color:rgb(99,99,186)'>P</span> <span style='color:rgb(113,113,157)'>A</span> <span style='color:rgb(89,89,206);font-weight:bold'>E</span> <span style='color:rgb(124,124,136)'>L</span> <span style='color:rgb(76,76,232);font-weight:bold'>E</span> <span style='color:rgb(104,104,175)'>A</span> <span style='color:rgb(138,123,123)'>I</span> <span style='color:rgb(117,117,149)'>V</span> <span style='color:rgb(102,102,179)'>T</span> <span style='color:rgb(148,118,118)'>T</span> <span style='color:rgb(120,120,144)'>A</span> <span style='color:rgb(101,101,181)'>E</span> <span style='color:rgb(106,106,171)'>K</span> <span style='color:rgb(137,123,123)'>I</span> <span style='color:rgb(101,101,181)'>A</span> <span style='color:rgb(98,98,188)'>P</span> <span style='color:rgb(104,104,175)'>L</span> <span style='color:rgb(105,105,173)'>I</span> <span style='color:rgb(128,128,128)'>S</span> <span style='color:rgb(110,110,164)'>E</span> <span style='color:rgb(101,101,181)'>N</span> <span style='color:rgb(98,98,187)'>E</span> <span style='color:rgb(109,109,166)'>T</span> <span style='color:rgb(112,112,159)'>F</span> <span style='color:rgb(101,101,181)'>A</span> <span style='color:rgb(109,109,166)'>V</span> <span style='color:rgb(112,112,159)'>K</span> <span style='color:rgb(115,115,154)'>T</span> <span style='color:rgb(101,101,181)'>K</span> <span style='color:rgb(108,108,168)'>R</span> <span style='color:rgb(113,113,158)'>R</span> <span style='color:rgb(96,96,191);font-weight:bold'>G</span> <span style='color:rgb(125,125,133)'>K</span> <span style='color:rgb(104,104,175)'>H</span> <span style='color:rgb(112,112,159)'>G</span> <span style='color:rgb(116,116,151)'>F</span> <span style='color:rgb(101,101,182)'>T</span> <span style='color:rgb(145,119,119)'>S</span> <span style='color:rgb(111,111,161)'>M</span> <span style='color:rgb(120,120,143)'>D</span> <span style='color:rgb(124,124,136)'>V</span> <span style='color:rgb(177,103,103)'>N</span> <span style='color:rgb(100,100,183)'>R</span> <span style='color:rgb(97,97,189)'>E</span> <span style='color:rgb(101,101,182)'>L</span> <span style='color:rgb(171,106,106)'>G</span> <span style='color:rgb(93,93,198);font-weight:bold'>A</span> <span style='color:rgb(97,97,189)'>R</span> <span style='color:rgb(89,89,206);font-weight:bold'>I</span> <span style='color:rgb(105,105,173)'>R</span> <span style='color:rgb(87,87,209);font-weight:bold'>E</span> <span style='color:rgb(104,104,175)'>L</span> <span style='color:rgb(118,118,148)'>T</span> <span style='color:rgb(109,109,166)'>N</span> <span style='color:rgb(111,111,161)'>A</span> <span style='color:rgb(93,93,197);font-weight:bold'>D</span> <span style='color:rgb(114,114,156)'>V</span> <span style='color:rgb(92,92,199);font-weight:bold'>N</span> <span style='color:rgb(184,100,100)'>L</span> <span style='color:rgb(125,125,134)'>S</span> <span style='color:rgb(78,78,228);font-weight:bold'>W</span> <span style='color:rgb(98,98,188)'>P</span> <span style='color:rgb(125,125,133)'>D</span> <span style='color:rgb(116,116,152)'>R</span> <span style='color:rgb(98,98,187)'>V</span> <span style='color:rgb(125,125,133)'>V</span> <span style='color:rgb(83,83,218);font-weight:bold'>Q</span> <span style='color:rgb(122,122,140)'>V</span> <span style='color:rgb(99,99,186)'>E</span> <span style='color:rgb(113,113,158)'>I</span> <span style='color:rgb(135,124,124)'>I</span> <span style='color:rgb(85,85,213);font-weight:bold'>G</span> <span style='color:rgb(129,127,127)'>D</span> <span style='color:rgb(98,98,188)'>K</span> <span style='color:rgb(107,107,169)'>A</span> <span style='color:rgb(118,118,147)'>Y</span> <span style='color:rgb(122,122,140)'>I</span> <span style='color:rgb(128,128,128)'>S</span> <span style='color:rgb(118,118,148)'>V</span> <span style='color:rgb(114,114,156)'>V</span> <span style='color:rgb(101,101,182)'>P</span> <span style='color:rgb(88,88,208);font-weight:bold'>G</span> <span style='color:rgb(106,106,171)'>E</span> <span style='color:rgb(125,125,134)'>E</span> <span style='color:rgb(110,110,164)'>F</span> <span style='color:rgb(121,121,142)'>R</span> <span style='color:rgb(97,97,189)'>K</span> <span style='color:rgb(121,121,142)'>F</span> <span style='color:rgb(104,104,176)'>T</span> <span style='color:rgb(103,103,177)'>P</span> <span style='color:rgb(123,123,137)'>D</span> <span style='color:rgb(120,120,144)'>K</span> <span style='color:rgb(118,118,148)'>I</span> <span style='color:rgb(111,111,161)'>D</span> <span style='color:rgb(109,109,165)'>A</span> <span style='color:rgb(112,112,159)'>R</span> <span style='color:rgb(105,105,173)'>K</span> <span style='color:rgb(111,111,162)'>L</span> <span style='color:rgb(113,113,157)'>F</span> <span style='color:rgb(106,106,172)'>R</span> <span style='color:rgb(96,96,191);font-weight:bold'>K</span> <span style='color:rgb(103,103,178)'>V</span> <span style='color:rgb(112,112,159)'>T</span> <span style='color:rgb(140,122,122)'>L</span> <span style='color:rgb(117,117,149)'>V</span> <span style='color:rgb(82,82,220);font-weight:bold'>Q</span> <span style='color:rgb(102,102,180)'>M</span> <span style='color:rgb(100,100,184)'>P</span> <span style='color:rgb(123,123,137)'>Y</span> <span style='color:rgb(108,108,168)'>W</span> <span style='color:rgb(111,111,162)'>G</span> <span style='color:rgb(116,116,152)'>N</span> <span style='color:rgb(95,95,194);font-weight:bold'>H</span> <span style='color:rgb(106,106,171)'>K</span> <span style='color:rgb(113,113,158)'>A</span> <span style='color:rgb(118,118,147)'>C</span> <span style='color:rgb(136,124,124)'>R</span> <span style='color:rgb(111,111,161)'>S</span> <span style='color:rgb(123,123,137)'>F</span> <span style='color:rgb(116,116,151)'>G</span> <span style='color:rgb(99,99,186)'>E</span> <span style='color:rgb(97,97,189)'>K</span> <span style='color:rgb(114,114,156)'>I</span> <span style='color:rgb(122,122,140)'>G</span> <span style='color:rgb(158,113,113)'>R</span> <span style='color:rgb(144,120,120)'>A</span> <span style='color:rgb(98,98,187)'>A</span> <span style='color:rgb(128,128,127)'>Q</span> <span style='color:rgb(155,114,114)'>A</span> <span style='color:rgb(174,105,105)'>F</span> <span style='color:rgb(118,118,148)'>E</span> <span style='color:rgb(109,109,165)'>V</span> <span style='color:rgb(68,68,247);font-weight:bold'>K</span> <span style='color:rgb(88,88,207);font-weight:bold'>E</span> <span style='color:rgb(123,123,138)'>L</span> <span style='color:rgb(117,117,149)'>I</span> <span style='color:rgb(124,124,136)'>I</span> <span style='color:rgb(109,109,166)'>A</span> <span style='color:rgb(104,104,175)'>P</span> <span style='color:rgb(98,98,187)'>K</span> <span style='color:rgb(105,105,173)'>E</span> <span style='color:rgb(121,121,142)'>K</span> <span style='color:rgb(104,104,175)'>M</span> <span style='color:rgb(96,96,192);font-weight:bold'>D</span> <span style='color:rgb(113,113,158)'>A</span> <span style='color:rgb(112,112,160)'>F</span> <span style='color:rgb(103,103,178)'>E</span> <span style='color:rgb(122,122,139)'>L</span> <span style='color:rgb(114,114,155)'>A</span> <span style='color:rgb(93,93,198);font-weight:bold'>E</span> <span style='color:rgb(108,108,168)'>F</span> <span style='color:rgb(107,107,169)'>I</span> <span style='color:rgb(109,109,165)'>K</span> <span style='color:rgb(98,98,188)'>G</span> <span style='color:rgb(121,121,142)'>V</span> <span style='color:rgb(96,96,192);font-weight:bold'>K</span> <span style='color:rgb(128,128,128)'>I</span> <span style='color:rgb(101,101,181)'>G</span> <span style='color:rgb(92,92,199);font-weight:bold'>Q</span> <span style='color:rgb(122,122,140)'>E</span> <span style='color:rgb(115,115,154)'>S</span> <span style='color:rgb(126,126,132)'>R</span> <span style='color:rgb(111,111,162)'>H</span> <span style='color:rgb(112,112,159)'>Q</span> <span style='color:rgb(119,119,146)'>I</span> <span style='color:rgb(94,94,196);font-weight:bold'>Q</span> <span style='color:rgb(111,111,162)'>R</span> <span style='color:rgb(106,106,172)'>E</span> <span style='color:rgb(116,116,151)'>A</span> <span style='color:rgb(120,120,144)'>Y</span> <span style='color:rgb(102,102,180)'>P</span> <span style='color:rgb(94,94,196);font-weight:bold'>W</span> <span style='color:rgb(116,116,151)'>K</span> <span style='color:rgb(105,105,174)'>V</span> <span style='color:rgb(114,114,156)'>E</span> <span style='color:rgb(121,121,142)'>K</span> <span style='color:rgb(110,110,163)'>V</span> <span style='color:rgb(90,90,204);font-weight:bold'>P</span> <span style='color:rgb(101,101,182)'>V</span> <span style='color:rgb(121,121,142)'>S</span> <span style='color:rgb(113,113,158)'>V</span> <span style='color:rgb(86,86,212);font-weight:bold'>W</span> <span style='color:rgb(110,110,163)'>D</span> <span style='color:rgb(115,115,153)'>L</span> <span style='color:rgb(114,114,155)'>Y</span> <span style='color:rgb(107,107,170)'>Q</span> <span style='color:rgb(127,128,128)'>V</span> <span style='color:rgb(133,125,125)'>V</span> <span style='color:rgb(112,112,160)'>R</span> <span style='color:rgb(140,122,122)'>D</span> <span style='color:rgb(85,85,214);font-weight:bold'>K</span> <span style='color:rgb(112,112,159)'>R</span> <span style='color:rgb(122,122,140)'>R</span> <span style='color:rgb(116,116,151)'>G</span> <span style='color:rgb(98,98,188)'>K</span> <span style='color:rgb(100,100,184)'>R</span> <span style='color:rgb(163,110,110)'>L</span> <span style='color:rgb(125,125,134)'>L</span> <span style='color:rgb(174,105,105)'>I</span> <span style='color:rgb(169,107,107)'>I</span> <span style='color:rgb(94,94,195);font-weight:bold'>T</span> <span style='color:rgb(125,125,133)'>D</span> <span style='color:rgb(86,86,212);font-weight:bold'>P</span> <span style='color:rgb(117,117,149)'>K</span> <span style='color:rgb(118,118,147)'>G</span> <span style='color:rgb(64,64,255);font-weight:bold'>P</span> <span style='color:rgb(93,93,197);font-weight:bold'>T</span> <span style='color:rgb(116,116,151)'>L</span> <span style='color:rgb(97,97,189)'>A</span> <span style='color:rgb(114,114,155)'>E</span> <span style='color:rgb(106,106,171)'>V</span> <span style='color:rgb(111,111,162)'>K</span> <span style='color:rgb(122,122,139)'>D</span> <span style='color:rgb(110,110,164)'>R</span> <span style='color:rgb(89,89,206);font-weight:bold'>L</span> <span style='color:rgb(119,119,145)'>A</span> <span style='color:rgb(100,100,184)'>K</span> <span style='color:rgb(104,104,176)'>D</span> <span style='color:rgb(119,119,145)'>M</span> <span style='color:rgb(117,117,150)'>F</span> <span style='color:rgb(99,99,186)'>Y</span> <span style='color:rgb(111,111,162)'>A</span> <span style='color:rgb(127,127,130)'>K</span> <span style='color:rgb(122,122,139)'>E</span> <span style='color:rgb(120,120,143)'>V</span> <span style='color:rgb(116,116,152)'>V</span> <span style='color:rgb(124,124,136)'>I</span> <span style='color:rgb(171,106,106)'>F</span> <span style='color:rgb(123,123,138)'>V</span> <span style='color:rgb(129,127,127)'>G</span> <span style='color:rgb(199,92,92);font-weight:bold'>S</span> <span style='color:rgb(102,102,180)'>R</span> <span style='color:rgb(114,114,156)'>E</span> <span style='color:rgb(203,90,90);font-weight:bold'>G</span> <span style='color:rgb(122,122,139)'>I</span> <span style='color:rgb(143,120,120)'>P</span> <span style='color:rgb(86,86,211);font-weight:bold'>R</span> <span style='color:rgb(72,72,239);font-weight:bold'>G</span> <span style='color:rgb(109,109,166)'>L</span> <span style='color:rgb(112,112,160)'>F</span> <span style='color:rgb(117,117,150)'>R</span> <span style='color:rgb(89,89,205);font-weight:bold'>F</span> <span style='color:rgb(109,109,166)'>A</span> <span style='color:rgb(106,106,172)'>D</span> <span style='color:rgb(98,98,188)'>Y</span> <span style='color:rgb(112,112,159)'>V</span> <span style='color:rgb(127,127,129)'>V</span> <span style='color:rgb(95,95,194);font-weight:bold'>D</span> <span style='color:rgb(111,111,162)'>L</span> <span style='color:rgb(93,93,197);font-weight:bold'>A</span> <span style='color:rgb(116,116,152)'>P</span> <span style='color:rgb(123,123,138)'>Y</span> <span style='color:rgb(189,97,97)'>M</span> <span style='color:rgb(99,99,185)'>T</span> <span style='color:rgb(116,116,152)'>F</span> <span style='color:rgb(96,96,192);font-weight:bold'>A</span> <span style='color:rgb(124,124,136)'>T</span> <span style='color:rgb(103,103,177)'>E</span> <span style='color:rgb(109,109,165)'>H</span> <span style='color:rgb(127,127,130)'>G</span> <span style='color:rgb(160,112,112)'>I</span> <span style='color:rgb(68,68,248);font-weight:bold'>P</span> <span style='color:rgb(103,103,178)'>A</span> <span style='color:rgb(117,117,149)'>A</span> <span style='color:rgb(161,111,111)'>L</span> <span style='color:rgb(96,96,191);font-weight:bold'>V</span> <span style='color:rgb(107,107,169)'>S</span> <span style='color:rgb(135,124,124)'>L</span> <span style='color:rgb(101,101,181)'>W</span> <span style='color:rgb(88,88,207);font-weight:bold'>E</span> <span style='color:rgb(92,92,199);font-weight:bold'>V</span> <span style='color:rgb(83,83,217);font-weight:bold'>Y</span> <span style='color:rgb(116,116,151)'>E</span> <span style='color:rgb(118,118,148)'>E</span> <span style='color:rgb(88,88,208);font-weight:bold'>Y</span> <span style='color:rgb(107,107,169)'>A</span> <span style='color:rgb(108,108,167)'>R</span> <span style='color:rgb(110,110,164)'>K</span> <span style='color:rgb(108,108,167)'>R</span> <span style='color:rgb(118,118,148)'>E</span> <span style='color:rgb(115,115,154)'>K</span> <span style='color:rgb(109,109,165)'>K</span> <span style='color:rgb(126,126,132)'>T</span> <span style='color:rgb(117,117,150)'>X</span> <span style='color:rgb(126,126,131)'>X</span> <span style='color:rgb(106,106,171)'>X</span> <span style='color:rgb(123,123,137)'>X</span> <span style='color:rgb(107,107,170)'>X</span> <span style='color:rgb(117,117,149)'>X</span> <span style='color:rgb(114,114,155)'>X</span> <span style='color:rgb(119,119,145)'>X</span> <span style='color:rgb(98,98,188)'>X</span> <span style='color:rgb(118,118,147)'>X</span> <span style='color:rgb(102,102,180)'>X</span> <span style='color:rgb(103,103,178)'>X</span> <span style='color:rgb(102,102,180)'>X</span> <span style='color:rgb(106,106,172)'>X</span> <span style='color:rgb(112,112,160)'>X</span> <span style='color:rgb(105,105,174)'>X</span> <span style='color:rgb(113,113,158)'>X</span> <span style='color:rgb(113,113,157)'>X</span> <span style='color:rgb(96,96,191);font-weight:bold'>X</span> <span style='color:rgb(127,128,128)'>X</span> <span style='color:rgb(104,104,176)'>X</span> <span style='color:rgb(110,110,164)'>X</span> <span style='color:rgb(114,114,156)'>X</span> <span style='color:rgb(112,112,159)'>X</span> <span style='color:rgb(103,103,178)'>X</span> <span style='color:rgb(123,123,137)'>X</span> <span style='color:rgb(104,104,175)'>X</span> <span style='color:rgb(112,112,159)'>X</span> <span style='color:rgb(102,102,180)'>X</span> <span style='color:rgb(118,118,148)'>X</span> <span style='color:rgb(102,102,179)'>X</span> <span style='color:rgb(110,110,163)'>X</span> <span style='color:rgb(110,110,164)'>X</span> <span style='color:rgb(107,107,170)'>X</span> <span style='color:rgb(103,103,177)'>X</span> <span style='color:rgb(121,121,142)'>X</span> <span style='color:rgb(101,101,182)'>X</span> <span style='color:rgb(113,113,158)'>X</span> <span style='color:rgb(116,116,151)'>X</span> <span style='color:rgb(107,107,169)'>X</span> <span style='color:rgb(113,113,158)'>X</span> <span style='color:rgb(112,112,160)'>X</span> <span style='color:rgb(109,109,166)'>X</span> <span style='color:rgb(110,110,163)'>X</span> <span style='color:rgb(114,114,156)'>X</span> <span style='color:rgb(115,115,154)'>X</span> <span style='color:rgb(110,110,163)'>X</span> <span style='color:rgb(108,108,168)'>X</span> <span style='color:rgb(114,114,156)'>X</span> <span style='color:rgb(114,114,155)'>X</span> <span style='color:rgb(107,107,170)'>X</span> <span style='color:rgb(117,117,149)'>X</span> <span style='color:rgb(105,105,173)'>X</span> <span style='color:rgb(123,123,137)'>X</span> <span style='color:rgb(99,99,186)'>X</span> <span style='color:rgb(122,122,139)'>X</span> <span style='color:rgb(94,94,195);font-weight:bold'>X</span> <span style='color:rgb(113,113,157)'>X</span> <span style='color:rgb(109,109,165)'>X</span> <span style='color:rgb(113,113,158)'>X</span> <span style='color:rgb(109,109,166)'>X</span> <span style='color:rgb(110,110,163)'>X</span> <span style='color:rgb(111,111,162)'>X</span> <span style='color:rgb(112,112,159)'>X</span> <span style='color:rgb(112,112,160)'>X</span> <span style='color:rgb(112,112,159)'>X</span> <span style='color:rgb(101,101,182)'>X</span> <span style='color:rgb(130,127,127)'>X</span> <span style='color:rgb(94,94,196);font-weight:bold'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(102,102,179)'>X</span> <span style='color:rgb(115,115,153)'>X</span> <span style='color:rgb(96,96,192);font-weight:bold'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(102,102,180)'>X</span> <span style='color:rgb(123,123,138)'>X</span> <span style='color:rgb(91,91,201);font-weight:bold'>X</span> <span style='color:rgb(115,115,154)'>X</span> <span style='color:rgb(105,105,174)'>X</span> <span style='color:rgb(110,110,164)'>X</span> <span style='color:rgb(112,112,159)'>X</span> <span style='color:rgb(107,107,170)'>X</span> <span style='color:rgb(99,99,186)'>X</span> <span style='color:rgb(124,124,136)'>X</span> <span style='color:rgb(101,101,181)'>X</span> <span style='color:rgb(115,115,153)'>X</span> <span style='color:rgb(110,110,163)'>X</span> <span style='color:rgb(115,115,154)'>X</span> <span style='color:rgb(106,106,172)'>X</span> <span style='color:rgb(123,123,138)'>X</span> <span style='color:rgb(104,104,176)'>X</span> <span style='color:rgb(123,123,138)'>X</span> <span style='color:rgb(93,93,197);font-weight:bold'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(95,95,193);font-weight:bold'>X</span> <span style='color:rgb(115,115,154)'>X</span> <span style='color:rgb(103,103,177)'>X</span> <span style='color:rgb(118,118,148)'>X</span> <span style='color:rgb(104,104,176)'>X</span> <span style='color:rgb(120,120,144)'>X</span> <span style='color:rgb(103,103,178)'>X</span> <span style='color:rgb(120,120,144)'>X</span> <span style='color:rgb(107,107,169)'>X</span> <span style='color:rgb(114,114,155)'>X</span> <span style='color:rgb(102,102,180)'>X</span> <span style='color:rgb(120,120,144)'>X</span> <span style='color:rgb(104,104,175)'>X</span> <span style='color:rgb(112,112,160)'>X</span> <span style='color:rgb(107,107,169)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(110,110,164)'>X</span> <span style='color:rgb(114,114,155)'>X</span> <span style='color:rgb(108,108,167)'>X</span> <span style='color:rgb(123,123,138)'>X</span> <span style='color:rgb(115,115,154)'>X</span> <span style='color:rgb(121,121,142)'>X</span> <span style='color:rgb(114,114,155)'>X</span> <span style='color:rgb(126,126,132)'>X</span> <span style='color:rgb(117,117,150)'>X</span> <span style='color:rgb(121,121,142)'>X</span> <span style='color:rgb(117,117,149)'>X</span> <span style='color:rgb(119,119,146)'>X</span> <span style='color:rgb(121,121,141)'>X</span> <span style='color:rgb(124,124,136)'>X</span> <span style='color:rgb(119,119,146)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(121,121,141)'>X</span> <span style='color:rgb(123,123,138)'>X</span> <span style='color:rgb(123,123,138)'>X</span> <span style='color:rgb(124,124,136)'>X</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(125,125,134)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(127,128,128)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(127,128,128)'>X</span> <span style='color:rgb(127,128,128)'>X</span> <span style='color:rgb(127,128,128)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(128,128,127)'>X</span>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "baseline = tf.zeros(shape=(500, 21))\n",
        "\n",
        "ig_attribution = integrated_gradients(model, baseline, seq_onehot)\n",
        "attrs = choose_validation_points(ig_attribution)\n",
        "\n",
        "visualisation = visualize_token_attrs(seq, attrs)\n",
        "HTML(visualisation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNydyZvHuQf4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}