{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_0L0XoBwzyID"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, BatchNormalization, MaxPooling1D, LSTM, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.random.set_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input csv file contains embeddings from ProtBert and labels (additional seq column is dropped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wPtKt_Zw1cNa"
   },
   "outputs": [],
   "source": [
    "df_embed = pd.read_csv('embeddings_clustered.csv', header=0).drop(columns=['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wizPXNnV-96I"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f1015</th>\n",
       "      <th>f1016</th>\n",
       "      <th>f1017</th>\n",
       "      <th>f1018</th>\n",
       "      <th>f1019</th>\n",
       "      <th>f1020</th>\n",
       "      <th>f1021</th>\n",
       "      <th>f1022</th>\n",
       "      <th>f1023</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008026</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>-0.002731</td>\n",
       "      <td>0.006590</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>-0.003621</td>\n",
       "      <td>-0.003674</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>-0.000830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011883</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>-0.009516</td>\n",
       "      <td>-0.008079</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>-0.000953</td>\n",
       "      <td>-0.006606</td>\n",
       "      <td>0.007095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.002169</td>\n",
       "      <td>0.014181</td>\n",
       "      <td>-0.003592</td>\n",
       "      <td>0.013964</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.008856</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025175</td>\n",
       "      <td>-0.005865</td>\n",
       "      <td>-0.008517</td>\n",
       "      <td>-0.034287</td>\n",
       "      <td>-0.009018</td>\n",
       "      <td>-0.001463</td>\n",
       "      <td>-0.005641</td>\n",
       "      <td>-0.015998</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009459</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>-0.007337</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.013372</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>-0.007039</td>\n",
       "      <td>-0.002837</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026371</td>\n",
       "      <td>-0.006343</td>\n",
       "      <td>-0.002163</td>\n",
       "      <td>-0.012372</td>\n",
       "      <td>-0.017190</td>\n",
       "      <td>-0.008411</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>-0.017102</td>\n",
       "      <td>0.008370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006879</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>-0.002314</td>\n",
       "      <td>0.009533</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>0.012066</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019255</td>\n",
       "      <td>-0.000503</td>\n",
       "      <td>-0.004768</td>\n",
       "      <td>-0.016739</td>\n",
       "      <td>-0.008599</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.005641</td>\n",
       "      <td>-0.013559</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.009244</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>-0.001748</td>\n",
       "      <td>-0.001447</td>\n",
       "      <td>-0.003295</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009760</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>-0.004179</td>\n",
       "      <td>-0.020035</td>\n",
       "      <td>-0.002772</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>-0.000919</td>\n",
       "      <td>-0.007066</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006307</td>\n",
       "      <td>-0.005468</td>\n",
       "      <td>-0.003098</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>-0.000381</td>\n",
       "      <td>-0.003291</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015195</td>\n",
       "      <td>-0.001228</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.007948</td>\n",
       "      <td>-0.009524</td>\n",
       "      <td>-0.001592</td>\n",
       "      <td>-0.007648</td>\n",
       "      <td>-0.005322</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>-0.000631</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>0.013168</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>-0.002288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021234</td>\n",
       "      <td>-0.007034</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>-0.008773</td>\n",
       "      <td>-0.009898</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>-0.009683</td>\n",
       "      <td>-0.020306</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005391</td>\n",
       "      <td>-0.000846</td>\n",
       "      <td>-0.002610</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>0.006229</td>\n",
       "      <td>0.007712</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>-0.003370</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>-0.000609</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010900</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>-0.004601</td>\n",
       "      <td>-0.021617</td>\n",
       "      <td>-0.002178</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-0.000871</td>\n",
       "      <td>-0.009249</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005580</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013708</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>-0.001832</td>\n",
       "      <td>-0.015929</td>\n",
       "      <td>-0.007805</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>-0.008558</td>\n",
       "      <td>-0.013434</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.014624</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.015161</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026249</td>\n",
       "      <td>-0.003871</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>-0.018174</td>\n",
       "      <td>-0.013056</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>-0.013903</td>\n",
       "      <td>-0.022747</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.008026  0.001627  0.002250 -0.002731  0.006590  0.004551 -0.003621   \n",
       "1  0.001079  0.000452 -0.002169  0.014181 -0.003592  0.013964  0.001270   \n",
       "2  0.009459  0.001682 -0.007337  0.018283  0.013372  0.018290  0.002750   \n",
       "3  0.006879  0.001830 -0.002314  0.009533  0.002879  0.012066  0.002401   \n",
       "4  0.005295  0.001240  0.001239  0.004125  0.001658  0.009244  0.000422   \n",
       "5  0.006307 -0.005468 -0.003098  0.006089  0.002296  0.005997 -0.000381   \n",
       "6  0.009253  0.005470 -0.000631  0.006090  0.009038  0.013168  0.003390   \n",
       "7  0.005391 -0.000846 -0.002610  0.004366  0.006229  0.007712  0.000440   \n",
       "8  0.005580  0.000895  0.000707  0.007481  0.002055  0.009236  0.001570   \n",
       "9  0.003823  0.004495  0.000049  0.014624  0.004590  0.015161  0.002902   \n",
       "\n",
       "         f7        f8        f9  ...     f1015     f1016     f1017     f1018  \\\n",
       "0 -0.003674  0.005713 -0.000830  ... -0.011883  0.003870  0.000411 -0.009516   \n",
       "1  0.000122  0.008856  0.005395  ... -0.025175 -0.005865 -0.008517 -0.034287   \n",
       "2 -0.007039 -0.002837  0.017166  ... -0.026371 -0.006343 -0.002163 -0.012372   \n",
       "3 -0.002095  0.005879  0.000577  ... -0.019255 -0.000503 -0.004768 -0.016739   \n",
       "4 -0.001748 -0.001447 -0.003295  ... -0.009760  0.002107 -0.004179 -0.020035   \n",
       "5 -0.003291  0.000421  0.008140  ... -0.015195 -0.001228 -0.000234 -0.007948   \n",
       "6  0.001653  0.001416 -0.002288  ... -0.021234 -0.007034  0.001915 -0.008773   \n",
       "7 -0.003370  0.000488 -0.000609  ... -0.010900 -0.000787 -0.004601 -0.021617   \n",
       "8 -0.002155  0.000254  0.003066  ... -0.013708  0.000873 -0.001832 -0.015929   \n",
       "9  0.002718  0.008350  0.006308  ... -0.026249 -0.003871 -0.000225 -0.018174   \n",
       "\n",
       "      f1019     f1020     f1021     f1022     f1023  label  \n",
       "0 -0.008079  0.000693 -0.000953 -0.006606  0.007095      1  \n",
       "1 -0.009018 -0.001463 -0.005641 -0.015998 -0.000411      1  \n",
       "2 -0.017190 -0.008411  0.000259 -0.017102  0.008370      1  \n",
       "3 -0.008599 -0.000422 -0.005641 -0.013559  0.001070      1  \n",
       "4 -0.002772  0.002291 -0.000919 -0.007066  0.002875      0  \n",
       "5 -0.009524 -0.001592 -0.007648 -0.005322  0.001370      1  \n",
       "6 -0.009898  0.002304 -0.009683 -0.020306  0.004665      1  \n",
       "7 -0.002178  0.000076 -0.000871 -0.009249  0.003401      1  \n",
       "8 -0.007805  0.001718 -0.008558 -0.013434  0.001748      1  \n",
       "9 -0.013056  0.000402 -0.013903 -0.022747  0.003118      1  \n",
       "\n",
       "[10 rows x 1025 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tbNG8OWy9NAh"
   },
   "outputs": [],
   "source": [
    "def make_train_test_dataset(df: pd.DataFrame, test_size: float = 0.2) -> Tuple[np.ndarray, np.ndarray,\n",
    "                                                                               np.ndarray, np.ndarray]:\n",
    "    df_train, df_test = train_test_split(df, test_size=test_size, random_state=42)\n",
    "\n",
    "    train_labels = df_train.pop('label').to_numpy()\n",
    "    test_labels = df_test.pop('label').to_numpy()\n",
    "\n",
    "    X_train = np.swapaxes(np.expand_dims(df_train, axis=1), 1, 2)\n",
    "    y_train = np.expand_dims(train_labels, axis=1)\n",
    "\n",
    "    X_test = np.swapaxes(np.expand_dims(df_test, axis=1), 1, 2)\n",
    "    y_test = np.expand_dims(test_labels, axis=1)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Qy38Hih3gny",
    "outputId": "2547c2f6-d24a-4376-c807-eda9b76af166"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = make_train_test_dataset(df_embed)\n",
    "del(df_embed)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "f3Qe7Hv9ozcG"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Conv1D(32, kernel_size=8, activation='relu', input_shape=(1024, 1)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(),\n",
    "        LSTM(20, dropout=0.3, recurrent_dropout=0.3),\n",
    "        Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kdh_hlJz4-N7",
    "outputId": "ad89ab0c-737c-4ccc-9d71-633c4f02396f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 1017, 32)          288       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1017, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 508, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 20)                4240      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,677\n",
      "Trainable params: 4,613\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ph_t27us4_S3",
    "outputId": "8b9cb70a-ed7c-476d-813c-29d7e5f239eb"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10\n",
    ")\n",
    "model.save(\"cnn_lstm_model.h5\", save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFHlOAaD5NA_",
    "outputId": "c7aa3623-5bc0-479b-de09-fa828849d5f2"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
