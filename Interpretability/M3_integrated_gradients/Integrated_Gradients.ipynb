{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "GWO08dGErDiT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MFO7oytsYB_L"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dropout, GlobalAveragePooling1D, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MSUVeyHtYb6C"
      },
      "outputs": [],
      "source": [
        "nucleo_dic = {\n",
        "    \"A\": 0,\n",
        "    \"R\": 1,\n",
        "    \"N\": 2,\n",
        "    \"D\": 3,\n",
        "    \"C\": 4,\n",
        "    \"Q\": 5,\n",
        "    \"E\": 6,\n",
        "    \"G\": 7,\n",
        "    \"H\": 8,\n",
        "    \"I\": 9,\n",
        "    \"L\": 10,\n",
        "    \"K\": 11,\n",
        "    \"M\": 12,\n",
        "    \"F\": 13,\n",
        "    \"P\": 14,\n",
        "    \"S\": 15,\n",
        "    \"T\": 16,\n",
        "    \"W\": 17,\n",
        "    \"Y\": 18,\n",
        "    \"V\": 19,\n",
        "    \"X\": 20\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKGAWOn1uQfv",
        "outputId": "69fc85a3-53a6-4454-e7bb-8196eb81de01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: 'git lfs clone' is deprecated and will not be updated\n",
            "          with new flags from 'git clone'\n",
            "\n",
            "'git clone' has been updated in upstream Git to have comparable\n",
            "speeds to 'git lfs clone'.\n",
            "Cloning into 'knots_simple_CNN'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 12 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (12/12), done.\n",
            "Git LFS: (1 of 1 files) 187.61 KB / 187.61 KB\n"
          ]
        }
      ],
      "source": [
        "!git lfs clone https://huggingface.co/EvaKlimentova/knots_simple_CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aJdOi11WhIhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0cf6023-93f9-4867-8945-110f2ed425ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_3 (Conv1D)           (None, 493, 32)           5408      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 493, 32)          128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 246, 32)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 239, 16)           4112      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 239, 16)          64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 119, 16)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 112, 4)            516       \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 112, 4)           16        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 56, 4)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 56, 4)             0         \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 4)                0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,249\n",
            "Trainable params: 10,145\n",
            "Non-trainable params: 104\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model('knots_simple_CNN/cnn_10epochs.h5')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbKn2pf5mgcw"
      },
      "source": [
        "## Integrated Gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DbphLAYIminT"
      },
      "outputs": [],
      "source": [
        "def generate_alphas(m_steps=50, method='riemann_trapezoidal'):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    m_steps(Tensor): A 0D tensor of an int corresponding to the number of linear\n",
        "    interpolation steps for computing an approximate integral. Default is 50.\n",
        "    method(str): A string representing the integral approximation method. The\n",
        "       following methods are implemented:\n",
        "      - riemann_trapezoidal(default)\n",
        "      - riemann_left\n",
        "      - riemann_midpoint\n",
        "      - riemann_right\n",
        "    Returns:\n",
        "      alphas(Tensor): A 1D tensor of uniformly spaced floats with the shape\n",
        "      (m_steps,).\n",
        "      \"\"\"\n",
        "    m_steps_float = tf.cast(m_steps, float)\n",
        "\n",
        "    if method == 'riemann_trapezoidal':\n",
        "        alphas = tf.linspace(0.0, 1.0, m_steps+1)\n",
        "    elif method == 'riemann_left':\n",
        "        alphas = tf.linspace(0.0, 1.0 - (1.0 / m_steps_float), m_steps)\n",
        "    elif method == 'riemann_midpoint':\n",
        "        alphas = tf.linspace(1.0 / (2.0 * m_steps_float), 1.0 - 1.0 / (2.0 * m_steps_float), m_steps)\n",
        "    elif method == 'riemann_right':\n",
        "        alphas = tf.linspace(1.0 / m_steps_float, 1.0, m_steps)\n",
        "    else:\n",
        "        raise AssertionError(\"Provided Riemann approximation method is not valid.\")\n",
        "\n",
        "    return alphas\n",
        "\n",
        "def generate_path_inputs(baseline, input, alphas):\n",
        "    \"\"\"\n",
        "    Generate interpolated 'images' along a linear path at alpha intervals between a baseline tensor\n",
        "\n",
        "    baseline: 2D, shape: (500, 21)\n",
        "    input: preprocessed sample, shape: (500, 21)\n",
        "    alphas: list of steps in interpolated image ,shape: (21)\n",
        "\n",
        "\n",
        "    return: shape (21, 500, 21)\n",
        "    \"\"\"\n",
        "    # Expand dimensions for vectorized computation of interpolations.\n",
        "    alphas_x = alphas[:, tf.newaxis, tf.newaxis]\n",
        "    baseline_x = tf.expand_dims(baseline, axis=0)\n",
        "    input_x = tf.expand_dims(input, axis=0)\n",
        "    delta = input_x - baseline_x\n",
        "    path_inputs = baseline_x + alphas_x * delta\n",
        "\n",
        "    return path_inputs\n",
        "\n",
        "def compute_gradients(model, path_inputs):\n",
        "    \"\"\"\n",
        "    compute dependency of each field on whole result, compared to interpolated 'images'\n",
        "\n",
        "    :param model: trained model\n",
        "    :param path_inputs: interpolated tensors, shape: (21, 500, 21)\n",
        "    :return: shape: (21, 500, 21)\n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(path_inputs)\n",
        "        predictions = model(path_inputs)\n",
        "\n",
        "        outputs = []\n",
        "        for envelope in predictions:\n",
        "            outputs.append(envelope[0])\n",
        "        outputs = tf.convert_to_tensor(outputs, dtype=tf.float32)\n",
        "\n",
        "    gradients = tape.gradient(outputs, path_inputs)\n",
        "    return gradients\n",
        "\n",
        "def integral_approximation(gradients, method='riemann_trapezoidal'):\n",
        "    \"\"\"Compute numerical approximation of integral from gradients.\n",
        "    Args:\n",
        "    gradients(Tensor): A 4D tensor of floats with the shape\n",
        "    (m_steps, img_height, img_width, 3).\n",
        "    method(str): A string representing the integral approximation method. The\n",
        "    following methods are implemented:\n",
        "    - riemann_trapezoidal(default)\n",
        "    - riemann_left\n",
        "    - riemann_midpoint\n",
        "    - riemann_right\n",
        "    Returns:\n",
        "    integrated_gradients(Tensor): A 3D tensor of floats with the shape\n",
        "    (img_height, img_width, 3).\n",
        "    \"\"\"\n",
        "    if method == 'riemann_trapezoidal':\n",
        "        grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n",
        "    elif method == 'riemann_left':\n",
        "        grads = gradients\n",
        "    elif method == 'riemann_midpoint':\n",
        "        grads = gradients\n",
        "    elif method == 'riemann_right':\n",
        "        grads = gradients\n",
        "    else:\n",
        "        raise AssertionError(\"Provided Riemann approximation method is not valid.\")\n",
        "\n",
        "    # Average integration approximation.\n",
        "    integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n",
        "\n",
        "    return integrated_gradients\n",
        "\n",
        "def integrated_gradients(model, baseline, input, m_steps=50, method='riemann_trapezoidal',\n",
        "                         batch_size=32):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      model(keras.Model): A trained model to generate predictions and inspect.\n",
        "      baseline(Tensor): 2D, shape: (500, 21)\n",
        "      input(Tensor): preprocessed sample, shape: (500, 21)\n",
        "      m_steps(Tensor): A 0D tensor of an integer corresponding to the number of\n",
        "        linear interpolation steps for computing an approximate integral.\n",
        "      method(str): A string representing the integral approximation method. The\n",
        "        following methods are implemented:\n",
        "        - riemann_trapezoidal(default)\n",
        "        - riemann_left\n",
        "        - riemann_midpoint\n",
        "        - riemann_right\n",
        "      batch_size(Tensor): A 0D tensor of an integer corresponding to a batch\n",
        "        size for alpha to scale computation and prevent OOM errors. Note: needs to\n",
        "        be tf.int64 and shoud be < m_steps. Default value is 32.\n",
        "    Returns:\n",
        "      integrated_gradients(Tensor): A 2D tensor of floats with the same\n",
        "        shape as the input tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Generate alphas.\n",
        "    alphas = generate_alphas(m_steps=m_steps,\n",
        "                             method=method)\n",
        "\n",
        "    # Initialize TensorArray outside loop to collect gradients. Note: this data structure\n",
        "    gradient_batches = tf.TensorArray(tf.float32, size=m_steps + 1)\n",
        "\n",
        "    # Iterate alphas range and batch computation for speed, memory efficiency, and scaling to larger m_steps.\n",
        "    for alpha in tf.range(0, len(alphas), batch_size):\n",
        "        from_ = alpha\n",
        "        to = tf.minimum(from_ + batch_size, len(alphas))\n",
        "        alpha_batch = alphas[from_:to]\n",
        "\n",
        "        # 2. Generate interpolated inputs between baseline and input.\n",
        "        interpolated_path_input_batch = generate_path_inputs(baseline=baseline,\n",
        "                                                             input=input,\n",
        "                                                             alphas=alpha_batch)\n",
        "\n",
        "        # 3. Compute gradients between model outputs and interpolated inputs.\n",
        "        gradient_batch = compute_gradients(model=model,\n",
        "                                           path_inputs=interpolated_path_input_batch)\n",
        "\n",
        "        # Write batch indices and gradients to TensorArray.\n",
        "        gradient_batches = gradient_batches.scatter(tf.range(from_, to), gradient_batch)\n",
        "\n",
        "    # Stack path gradients together row-wise into single tensor.\n",
        "    total_gradients = gradient_batches.stack()\n",
        "\n",
        "    # 4. Integral approximation through averaging gradients.\n",
        "    avg_gradients = integral_approximation(gradients=total_gradients,\n",
        "                                           method=method)\n",
        "\n",
        "    # 5. Scale integrated gradients with respect to input.\n",
        "    integrated_gradients = (input - baseline) * avg_gradients\n",
        "\n",
        "    return integrated_gradients\n",
        "\n",
        "def choose_validation_points(integrated_gradients):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "          integrated_gradients(Tensor): A 2D tensor of floats with shape (500, 21).\n",
        "    Return: List of attributes for highlighting protein sequence\n",
        "    \"\"\"\n",
        "    attr = np.zeros(500)\n",
        "    for i in range(500):\n",
        "        for j in range(21):\n",
        "            if integrated_gradients[i][j].numpy() == 0:\n",
        "                continue\n",
        "            attr[i] = integrated_gradients[i][j].numpy()\n",
        "    return attr\n",
        "\n",
        "def visualize_token_attrs(sequence, attrs):\n",
        "    \"\"\"\n",
        "    Visualize attributions for given set of tokens.\n",
        "    Args:\n",
        "    - tokens: An array of tokens\n",
        "    - attrs: An array of attributions, of same size as 'tokens',\n",
        "      with attrs[i] being the attribution to tokens[i]\n",
        "\n",
        "    Returns:\n",
        "    - visualization: HTML text with colorful representation of protein sequence\n",
        "        build on model prediction\n",
        "    \"\"\"\n",
        "\n",
        "    def get_color(attr):\n",
        "        if attr > 0:\n",
        "            red = int(128 * attr) + 127\n",
        "            green = 128 - int(64 * attr)\n",
        "            blue = 128 - int(64 * attr)\n",
        "        else:\n",
        "            red = 128 + int(64 * attr)\n",
        "            green = 128 + int(64 * attr)\n",
        "            blue = int(-128 * attr) + 127\n",
        "\n",
        "        return red, green, blue\n",
        "\n",
        "    # normalize attributions for visualization.\n",
        "    bound = max(abs(max(attrs)), abs(min(attrs)))\n",
        "    attrs = attrs / bound\n",
        "    html_text = \"\"\n",
        "    for i, tok in enumerate(sequence):\n",
        "        r, g, b = get_color(attrs[i])\n",
        "        if abs(attrs[i]) > 0.5:\n",
        "          html_text += \" <span style='color:rgb(%d,%d,%d);font-weight:bold'>%s</span>\" % (r, g, b, tok)\n",
        "        else: \n",
        "          html_text += \" <span style='color:rgb(%d,%d,%d)'>%s</span>\" % (r, g, b, tok)\n",
        "\n",
        "    return html_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SBhmsvbdrS9"
      },
      "source": [
        "## Input your sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ec-Fg1lPuQf1"
      },
      "outputs": [],
      "source": [
        "seq = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "adjust the sequence to be 500 amino acids long"
      ],
      "metadata": {
        "id": "jCAJF_T6qqkN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qksmbvWhuQf1",
        "outputId": "43adc89c-672c-4477-f672-73c287cda68e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MKFIVKTQRGMESVAANYIREAISDASVWASPMGYSGLIIVETSDENAGEKILEIPEVERLIPVIAEVPAELEAIVTTAEKIAPLISENETFAVKTKRRGKHGFTSMDVNRELGARIRELTNADVNLSWPDRVVQVEIIGDKAYISVVPGEEFRKFTPDKIDARKLFRKVTLVQMPYWGNHKACRSFGEKIGRAAQAFEVKELIIAPKEKMDAFELAEFIKGVKIGQESRHQIQREAYPWKVEKVPVSVWDLYQVVRDKRRGKRLLIITDPKGPTLAEVKDRLAKDMFYAKEVVIFVGSREGIPRGLFRFADYVVDLAPYMTFATEHGIPAALVSLWEVYEEYARKREKKTXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n"
          ]
        }
      ],
      "source": [
        "if len(seq) > 500:\n",
        "    seq = seq[:500]\n",
        "else:\n",
        "    seq = seq + (500 - len(seq))*'X'\n",
        "    \n",
        "print(seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SljAsEIquQf2"
      },
      "source": [
        "-------------------------------------------------------------------------------------\n",
        "### or try out one of the prepared sequences:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNW8PmvPuQf2"
      },
      "source": [
        "Positive sequence example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Qrhuy5_suQf3"
      },
      "outputs": [],
      "source": [
        "seq = 'MAQQEWLFGLHALQAVLEREPERILELMVLKGRTDERLGEIINQARRFGVSVQFCHRKVLDEKVGGSQHQGVVARAKPARALDENDLAVIVERADKPFLLVLDGVTDPHNLGACLRTADAAGVDAVIVPKDKSASLSGTVSKVACGAAETMPLVQVTNLARTLKTLQEAGVWIIGTAGETTQTLYDTRLDGPMALVMGAEGKGMRRLTRETCDELVKLPMAGSVSSLNVSVATGVCLYEVVRQRQQXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HWeUESYuQf3"
      },
      "source": [
        "Negative sequence example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OWZk0dSuQf3"
      },
      "outputs": [],
      "source": [
        "seq = 'MAYTVVWFKRDLRVHDHAPLAHAAAHGPVLCLYVLEPSLWAQPDSALQHYQFLRESLRDLAQQLRSCGARLQLAVGETPEVLARLYALQPFARLVSHEETGNGATYARDLAVARWCRRQGVAWQEWPQHGVVRRLPSREQWHGLWQAHMQAPCLPPPLPASLRSVCLPWRDTWPAPETMGLSDAHDPPQRQRGGRAPGQQVLHDFLHARAAFYRGGISSPLTAPTACSRLSPYLALGCLGMREAVQATQQRQVQLKLQDAQQAAHVRQAFLAQFGQHGGGGDVGVPLRTALMRRVREDGRRYAVNLVIGQRVIAAQRGGAGSETGCELHGLSPDEKGLLFKPHTGFLDSEPSLSAVLCGWHEEPGWPCCHRLSXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCbOuC4auQf3"
      },
      "source": [
        "-------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "encode the sequence"
      ],
      "metadata": {
        "id": "44lNbQXYq2Gn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlkegTxYn36E",
        "outputId": "916a7bf3-5b9f-4c70-8813-9211680f592a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([500, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "seq_onehot = tf.one_hot([nucleo_dic[c] for c in seq], depth=21)\n",
        "\n",
        "seq_onehot.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "run integrated gradients and their visualization"
      ],
      "metadata": {
        "id": "iVLbdz0vq5XM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "DcEBQDxlokr0",
        "outputId": "78b76ea0-5272-45ee-a696-b2ff5bcf852c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " <span style='color:rgb(128,128,128)'>M</span> <span style='color:rgb(129,127,127)'>A</span> <span style='color:rgb(128,128,128)'>Q</span> <span style='color:rgb(128,128,128)'>Q</span> <span style='color:rgb(128,128,128)'>E</span> <span style='color:rgb(128,128,128)'>W</span> <span style='color:rgb(125,125,134)'>L</span> <span style='color:rgb(128,128,128)'>F</span> <span style='color:rgb(128,128,128)'>G</span> <span style='color:rgb(134,125,125)'>L</span> <span style='color:rgb(130,127,127)'>H</span> <span style='color:rgb(127,127,129)'>A</span> <span style='color:rgb(128,128,128)'>L</span> <span style='color:rgb(126,126,131)'>Q</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(128,128,128)'>V</span> <span style='color:rgb(127,128,128)'>L</span> <span style='color:rgb(129,127,127)'>E</span> <span style='color:rgb(128,128,127)'>R</span> <span style='color:rgb(127,128,128)'>E</span> <span style='color:rgb(125,125,134)'>P</span> <span style='color:rgb(127,127,129)'>E</span> <span style='color:rgb(128,128,127)'>R</span> <span style='color:rgb(127,128,128)'>I</span> <span style='color:rgb(123,123,138)'>L</span> <span style='color:rgb(139,122,122)'>E</span> <span style='color:rgb(134,125,125)'>L</span> <span style='color:rgb(128,128,127)'>M</span> <span style='color:rgb(119,119,146)'>V</span> <span style='color:rgb(129,127,127)'>L</span> <span style='color:rgb(128,128,128)'>K</span> <span style='color:rgb(129,127,127)'>G</span> <span style='color:rgb(127,127,129)'>R</span> <span style='color:rgb(124,124,135)'>T</span> <span style='color:rgb(119,119,145)'>D</span> <span style='color:rgb(124,124,136)'>E</span> <span style='color:rgb(150,117,117)'>R</span> <span style='color:rgb(127,127,130)'>L</span> <span style='color:rgb(141,121,121)'>G</span> <span style='color:rgb(141,121,121)'>E</span> <span style='color:rgb(127,127,130)'>I</span> <span style='color:rgb(137,123,123)'>I</span> <span style='color:rgb(127,127,129)'>N</span> <span style='color:rgb(128,128,128)'>Q</span> <span style='color:rgb(132,126,126)'>A</span> <span style='color:rgb(123,123,138)'>R</span> <span style='color:rgb(120,120,143)'>R</span> <span style='color:rgb(128,128,128)'>F</span> <span style='color:rgb(144,120,120)'>G</span> <span style='color:rgb(124,124,135)'>V</span> <span style='color:rgb(116,116,152)'>S</span> <span style='color:rgb(123,123,137)'>V</span> <span style='color:rgb(133,125,125)'>Q</span> <span style='color:rgb(124,124,135)'>F</span> <span style='color:rgb(120,120,143)'>C</span> <span style='color:rgb(143,120,120)'>H</span> <span style='color:rgb(124,124,136)'>R</span> <span style='color:rgb(126,126,131)'>K</span> <span style='color:rgb(126,126,131)'>V</span> <span style='color:rgb(134,125,125)'>L</span> <span style='color:rgb(127,127,130)'>D</span> <span style='color:rgb(122,122,139)'>E</span> <span style='color:rgb(150,117,117)'>K</span> <span style='color:rgb(132,126,126)'>V</span> <span style='color:rgb(123,123,137)'>G</span> <span style='color:rgb(122,122,140)'>G</span> <span style='color:rgb(123,123,137)'>S</span> <span style='color:rgb(120,120,143)'>Q</span> <span style='color:rgb(135,124,124)'>H</span> <span style='color:rgb(130,127,127)'>Q</span> <span style='color:rgb(152,116,116)'>G</span> <span style='color:rgb(128,128,128)'>V</span> <span style='color:rgb(127,127,129)'>V</span> <span style='color:rgb(127,127,130)'>A</span> <span style='color:rgb(141,121,121)'>R</span> <span style='color:rgb(129,127,127)'>A</span> <span style='color:rgb(126,126,132)'>K</span> <span style='color:rgb(122,122,139)'>P</span> <span style='color:rgb(136,124,124)'>A</span> <span style='color:rgb(117,117,150)'>R</span> <span style='color:rgb(125,125,134)'>A</span> <span style='color:rgb(132,126,126)'>L</span> <span style='color:rgb(127,128,128)'>D</span> <span style='color:rgb(135,124,124)'>E</span> <span style='color:rgb(140,122,122)'>N</span> <span style='color:rgb(136,124,124)'>D</span> <span style='color:rgb(128,128,128)'>L</span> <span style='color:rgb(126,126,132)'>A</span> <span style='color:rgb(116,116,151)'>V</span> <span style='color:rgb(127,127,130)'>I</span> <span style='color:rgb(126,126,131)'>V</span> <span style='color:rgb(137,123,123)'>E</span> <span style='color:rgb(132,126,126)'>R</span> <span style='color:rgb(129,127,127)'>A</span> <span style='color:rgb(165,109,109)'>D</span> <span style='color:rgb(125,125,134)'>K</span> <span style='color:rgb(177,103,103)'>P</span> <span style='color:rgb(127,127,130)'>F</span> <span style='color:rgb(116,116,152)'>L</span> <span style='color:rgb(150,117,117)'>L</span> <span style='color:rgb(149,117,117)'>V</span> <span style='color:rgb(200,92,92);font-weight:bold'>L</span> <span style='color:rgb(145,119,119)'>D</span> <span style='color:rgb(114,114,155)'>G</span> <span style='color:rgb(137,123,123)'>V</span> <span style='color:rgb(125,125,133)'>T</span> <span style='color:rgb(141,121,121)'>D</span> <span style='color:rgb(183,100,100)'>P</span> <span style='color:rgb(116,116,152)'>H</span> <span style='color:rgb(255,64,64);font-weight:bold'>N</span> <span style='color:rgb(222,81,81);font-weight:bold'>L</span> <span style='color:rgb(237,73,73);font-weight:bold'>G</span> <span style='color:rgb(98,98,187)'>A</span> <span style='color:rgb(214,85,85);font-weight:bold'>C</span> <span style='color:rgb(116,116,151)'>L</span> <span style='color:rgb(223,80,80);font-weight:bold'>R</span> <span style='color:rgb(167,108,108)'>T</span> <span style='color:rgb(182,101,101)'>A</span> <span style='color:rgb(127,127,130)'>D</span> <span style='color:rgb(186,99,99)'>A</span> <span style='color:rgb(126,126,131)'>A</span> <span style='color:rgb(120,120,143)'>G</span> <span style='color:rgb(127,128,128)'>V</span> <span style='color:rgb(115,115,153)'>D</span> <span style='color:rgb(133,125,125)'>A</span> <span style='color:rgb(125,125,133)'>V</span> <span style='color:rgb(127,127,129)'>I</span> <span style='color:rgb(118,118,147)'>V</span> <span style='color:rgb(126,126,131)'>P</span> <span style='color:rgb(135,124,124)'>K</span> <span style='color:rgb(123,123,137)'>D</span> <span style='color:rgb(128,128,128)'>K</span> <span style='color:rgb(138,123,123)'>S</span> <span style='color:rgb(126,126,131)'>A</span> <span style='color:rgb(142,121,121)'>S</span> <span style='color:rgb(145,119,119)'>L</span> <span style='color:rgb(128,128,128)'>S</span> <span style='color:rgb(105,105,173)'>G</span> <span style='color:rgb(158,113,113)'>T</span> <span style='color:rgb(120,120,144)'>V</span> <span style='color:rgb(118,118,148)'>S</span> <span style='color:rgb(148,118,118)'>K</span> <span style='color:rgb(121,121,141)'>V</span> <span style='color:rgb(129,127,127)'>A</span> <span style='color:rgb(124,124,135)'>C</span> <span style='color:rgb(119,119,145)'>G</span> <span style='color:rgb(133,125,125)'>A</span> <span style='color:rgb(119,119,146)'>A</span> <span style='color:rgb(159,112,112)'>E</span> <span style='color:rgb(181,101,101)'>T</span> <span style='color:rgb(127,128,128)'>M</span> <span style='color:rgb(214,85,85);font-weight:bold'>P</span> <span style='color:rgb(143,120,120)'>L</span> <span style='color:rgb(163,110,110)'>V</span> <span style='color:rgb(107,107,170)'>Q</span> <span style='color:rgb(165,109,109)'>V</span> <span style='color:rgb(196,94,94);font-weight:bold'>T</span> <span style='color:rgb(117,117,149)'>N</span> <span style='color:rgb(124,124,136)'>L</span> <span style='color:rgb(142,121,121)'>A</span> <span style='color:rgb(131,126,126)'>R</span> <span style='color:rgb(147,118,118)'>T</span> <span style='color:rgb(135,124,124)'>L</span> <span style='color:rgb(89,89,206);font-weight:bold'>K</span> <span style='color:rgb(120,120,144)'>T</span> <span style='color:rgb(162,111,111)'>L</span> <span style='color:rgb(118,118,147)'>Q</span> <span style='color:rgb(186,99,99)'>E</span> <span style='color:rgb(122,122,139)'>A</span> <span style='color:rgb(125,125,133)'>G</span> <span style='color:rgb(105,105,173)'>V</span> <span style='color:rgb(126,126,132)'>W</span> <span style='color:rgb(128,128,128)'>I</span> <span style='color:rgb(142,121,121)'>I</span> <span style='color:rgb(143,120,120)'>G</span> <span style='color:rgb(155,114,114)'>T</span> <span style='color:rgb(124,124,136)'>A</span> <span style='color:rgb(123,123,138)'>G</span> <span style='color:rgb(121,121,141)'>E</span> <span style='color:rgb(121,121,142)'>T</span> <span style='color:rgb(129,127,127)'>T</span> <span style='color:rgb(134,125,125)'>Q</span> <span style='color:rgb(143,120,120)'>T</span> <span style='color:rgb(145,119,119)'>L</span> <span style='color:rgb(131,126,126)'>Y</span> <span style='color:rgb(167,108,108)'>D</span> <span style='color:rgb(132,126,126)'>T</span> <span style='color:rgb(112,112,159)'>R</span> <span style='color:rgb(143,120,120)'>L</span> <span style='color:rgb(149,117,117)'>D</span> <span style='color:rgb(189,97,97)'>G</span> <span style='color:rgb(177,103,103)'>P</span> <span style='color:rgb(107,107,169)'>M</span> <span style='color:rgb(129,127,127)'>A</span> <span style='color:rgb(179,102,102)'>L</span> <span style='color:rgb(170,107,107)'>V</span> <span style='color:rgb(128,128,128)'>M</span> <span style='color:rgb(245,69,69);font-weight:bold'>G</span> <span style='color:rgb(122,122,139)'>A</span> <span style='color:rgb(207,88,88);font-weight:bold'>E</span> <span style='color:rgb(232,76,76);font-weight:bold'>G</span> <span style='color:rgb(132,126,126)'>K</span> <span style='color:rgb(156,114,114)'>G</span> <span style='color:rgb(129,127,127)'>M</span> <span style='color:rgb(128,128,128)'>R</span> <span style='color:rgb(134,125,125)'>R</span> <span style='color:rgb(128,128,128)'>L</span> <span style='color:rgb(127,128,128)'>T</span> <span style='color:rgb(127,127,130)'>R</span> <span style='color:rgb(125,125,133)'>E</span> <span style='color:rgb(127,127,130)'>T</span> <span style='color:rgb(125,125,133)'>C</span> <span style='color:rgb(122,122,140)'>D</span> <span style='color:rgb(127,127,130)'>E</span> <span style='color:rgb(127,127,130)'>L</span> <span style='color:rgb(122,122,139)'>V</span> <span style='color:rgb(133,125,125)'>K</span> <span style='color:rgb(130,127,127)'>L</span> <span style='color:rgb(168,108,108)'>P</span> <span style='color:rgb(125,125,133)'>M</span> <span style='color:rgb(130,127,127)'>A</span> <span style='color:rgb(116,116,152)'>G</span> <span style='color:rgb(127,127,129)'>S</span> <span style='color:rgb(138,123,123)'>V</span> <span style='color:rgb(120,120,143)'>S</span> <span style='color:rgb(203,90,90);font-weight:bold'>S</span> <span style='color:rgb(209,87,87);font-weight:bold'>L</span> <span style='color:rgb(215,84,84);font-weight:bold'>N</span> <span style='color:rgb(209,87,87);font-weight:bold'>V</span> <span style='color:rgb(146,119,119)'>S</span> <span style='color:rgb(97,97,189)'>V</span> <span style='color:rgb(193,95,95);font-weight:bold'>A</span> <span style='color:rgb(88,88,208);font-weight:bold'>T</span> <span style='color:rgb(92,92,200);font-weight:bold'>G</span> <span style='color:rgb(171,106,106)'>V</span> <span style='color:rgb(139,122,122)'>C</span> <span style='color:rgb(236,74,74);font-weight:bold'>L</span> <span style='color:rgb(200,92,92);font-weight:bold'>Y</span> <span style='color:rgb(137,123,123)'>E</span> <span style='color:rgb(121,121,141)'>V</span> <span style='color:rgb(103,103,178)'>V</span> <span style='color:rgb(143,120,120)'>R</span> <span style='color:rgb(130,127,127)'>Q</span> <span style='color:rgb(128,128,128)'>R</span> <span style='color:rgb(132,126,126)'>Q</span> <span style='color:rgb(160,112,112)'>Q</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(134,125,125)'>X</span> <span style='color:rgb(150,117,117)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(131,126,126)'>X</span> <span style='color:rgb(147,118,118)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(136,124,124)'>X</span> <span style='color:rgb(139,122,122)'>X</span> <span style='color:rgb(122,122,139)'>X</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(119,119,145)'>X</span> <span style='color:rgb(120,120,144)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(123,123,137)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(121,121,141)'>X</span> <span style='color:rgb(129,127,127)'>X</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(119,119,145)'>X</span> <span style='color:rgb(122,122,139)'>X</span> <span style='color:rgb(127,128,128)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(121,121,142)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(120,120,143)'>X</span> <span style='color:rgb(120,120,143)'>X</span> <span style='color:rgb(123,123,137)'>X</span> <span style='color:rgb(127,128,128)'>X</span> <span style='color:rgb(120,120,144)'>X</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(117,117,150)'>X</span> <span style='color:rgb(129,127,127)'>X</span> <span style='color:rgb(116,116,152)'>X</span> <span style='color:rgb(130,127,127)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(125,125,134)'>X</span> <span style='color:rgb(121,121,141)'>X</span> <span style='color:rgb(126,126,131)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(115,115,153)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(124,124,136)'>X</span> <span style='color:rgb(122,122,139)'>X</span> <span style='color:rgb(123,123,138)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(120,120,144)'>X</span> <span style='color:rgb(122,122,139)'>X</span> <span style='color:rgb(124,124,136)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(121,121,142)'>X</span> <span style='color:rgb(125,125,134)'>X</span> <span style='color:rgb(126,126,132)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(123,123,138)'>X</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(121,121,142)'>X</span> <span style='color:rgb(123,123,137)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(118,118,147)'>X</span> <span style='color:rgb(126,126,132)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(123,123,138)'>X</span> <span style='color:rgb(122,122,139)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(126,126,132)'>X</span> <span style='color:rgb(116,116,151)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(121,121,141)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(119,119,146)'>X</span> <span style='color:rgb(119,119,145)'>X</span> <span style='color:rgb(126,126,131)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(121,121,142)'>X</span> <span style='color:rgb(123,123,138)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(126,126,132)'>X</span> <span style='color:rgb(118,118,147)'>X</span> <span style='color:rgb(126,126,131)'>X</span> <span style='color:rgb(126,126,131)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(120,120,144)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(131,126,126)'>X</span> <span style='color:rgb(115,115,153)'>X</span> <span style='color:rgb(121,121,141)'>X</span> <span style='color:rgb(122,122,139)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(121,121,141)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(123,123,137)'>X</span> <span style='color:rgb(126,126,132)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(123,123,138)'>X</span> <span style='color:rgb(125,125,134)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(114,114,155)'>X</span> <span style='color:rgb(124,124,136)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(123,123,137)'>X</span> <span style='color:rgb(124,124,136)'>X</span> <span style='color:rgb(121,121,141)'>X</span> <span style='color:rgb(127,128,128)'>X</span> <span style='color:rgb(126,126,131)'>X</span> <span style='color:rgb(118,118,147)'>X</span> <span style='color:rgb(122,122,139)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(126,126,132)'>X</span> <span style='color:rgb(122,122,139)'>X</span> <span style='color:rgb(121,121,141)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(121,121,142)'>X</span> <span style='color:rgb(126,126,132)'>X</span> <span style='color:rgb(120,120,144)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(118,118,148)'>X</span> <span style='color:rgb(124,124,136)'>X</span> <span style='color:rgb(121,121,141)'>X</span> <span style='color:rgb(129,127,127)'>X</span> <span style='color:rgb(117,117,149)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(127,128,128)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(123,123,137)'>X</span> <span style='color:rgb(120,120,144)'>X</span> <span style='color:rgb(126,126,131)'>X</span> <span style='color:rgb(125,125,134)'>X</span> <span style='color:rgb(118,118,147)'>X</span> <span style='color:rgb(123,123,137)'>X</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(122,122,139)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(120,120,143)'>X</span> <span style='color:rgb(126,126,132)'>X</span> <span style='color:rgb(125,125,134)'>X</span> <span style='color:rgb(119,119,146)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(121,121,142)'>X</span> <span style='color:rgb(126,126,131)'>X</span> <span style='color:rgb(122,122,139)'>X</span> <span style='color:rgb(127,128,128)'>X</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(123,123,137)'>X</span> <span style='color:rgb(118,118,147)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(118,118,147)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(124,124,136)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(125,125,134)'>X</span> <span style='color:rgb(126,126,131)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(121,121,142)'>X</span> <span style='color:rgb(126,126,132)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(120,120,143)'>X</span> <span style='color:rgb(129,127,127)'>X</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(118,118,147)'>X</span> <span style='color:rgb(124,124,136)'>X</span> <span style='color:rgb(125,125,134)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(118,118,148)'>X</span> <span style='color:rgb(123,123,138)'>X</span> <span style='color:rgb(125,125,134)'>X</span> <span style='color:rgb(126,126,131)'>X</span> <span style='color:rgb(122,122,140)'>X</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(120,120,143)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(122,122,139)'>X</span> <span style='color:rgb(127,128,128)'>X</span> <span style='color:rgb(117,117,150)'>X</span> <span style='color:rgb(125,125,134)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(121,121,142)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(124,124,136)'>X</span> <span style='color:rgb(122,122,139)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(116,116,152)'>X</span> <span style='color:rgb(124,124,136)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(123,123,137)'>X</span> <span style='color:rgb(121,121,142)'>X</span> <span style='color:rgb(121,121,142)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(119,119,146)'>X</span> <span style='color:rgb(120,120,144)'>X</span> <span style='color:rgb(125,125,134)'>X</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(121,121,141)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(121,121,141)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(121,121,142)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(120,120,143)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(123,123,137)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(126,126,132)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(125,125,134)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(124,124,135)'>X</span> <span style='color:rgb(125,125,133)'>X</span> <span style='color:rgb(126,126,131)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(126,126,131)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(127,127,130)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(127,127,129)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(128,128,128)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(127,128,128)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(128,128,127)'>X</span> <span style='color:rgb(128,128,127)'>X</span>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "baseline = tf.zeros(shape=(500, 21))\n",
        "\n",
        "ig_attribution = integrated_gradients(model, baseline, seq_onehot, m_steps=200)\n",
        "attrs = choose_validation_points(ig_attribution)\n",
        "\n",
        "visualisation = visualize_token_attrs(seq, attrs)\n",
        "HTML(visualisation)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model score for the input sequence:"
      ],
      "metadata": {
        "id": "44kDu9zGrgbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(np.expand_dims(seq_onehot, axis=0), verbose=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1okwf3MrfaS",
        "outputId": "835cc220-9204-4a98-fe27-d663b20701fe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.99997294]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Color explanation:**\n",
        "**Red** amino acids influences the model to think the protein is knotted\n",
        "\n",
        "**Blue** amino acids influences the model to think the protein is unknotted"
      ],
      "metadata": {
        "id": "ZC3N-C0bqQHS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNydyZvHuQf4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}