{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e692cd1f-0226-4fa7-93ec-2e35d6502809",
   "metadata": {},
   "source": [
    "# Generate embeddings for M2 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b2c5f4-ce32-4392-9e96-0f5c52e0629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9059976-0cef-4953-877b-1bd7554ad9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 40\n",
    "HF_DATASET = f'roa7n/patched_1000_test_p_{PATCH_SIZE}'\n",
    "OUTPUT = f'/home/jovyan/data/proteins_m2/patched_{PATCH_SIZE}_embeddings_backup.csv'\n",
    "HF_OUTPUT = f'roa7n/patched_1000_test_p_{PATCH_SIZE}_m2_embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416bd867-cff9-4ba8-ac6c-accefbf3623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b2d1ab-46c4-4ea1-a850-d750c05ffb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration roa7n--patched_1000_test_p_40-3d7a1ccf9152eda0\n",
      "Found cached dataset parquet (/home/jovyan/.cache/huggingface/datasets/roa7n___parquet/roa7n--patched_1000_test_p_40-3d7a1ccf9152eda0/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026490e403d645f1acd0f71c9628159e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'sequence_str', 'label'],\n",
       "        num_rows: 1663294\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset = load_dataset(HF_DATASET)\n",
    "hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9996b46a-6afe-404a-80ac-6dae3955132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1663294, 3)\n"
     ]
    }
   ],
   "source": [
    "df = hf_dataset['train'].to_pandas()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615e006b-c0ef-4e58-8f0a-14ed7c3e40e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence_str</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A533UME0_40_-1</td>\n",
       "      <td>MKLSIAIPDSSVSDESTQLGKSMKISLIARACAIFRVQTVYIYHES...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A533UME0_40_0</td>\n",
       "      <td>XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXYIYHES...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A533UME0_40_1</td>\n",
       "      <td>MXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXIYHES...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A533UME0_40_2</td>\n",
       "      <td>MKXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXYHES...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A533UME0_40_3</td>\n",
       "      <td>MKLXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXHES...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663289</th>\n",
       "      <td>A0A6A4IYK5_40_292</td>\n",
       "      <td>MSYNDGNWCLIESDPGVFSELIREFGCSGVQVEEIWSLEAGQFEDL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663290</th>\n",
       "      <td>A0A6A4IYK5_40_293</td>\n",
       "      <td>MSYNDGNWCLIESDPGVFSELIREFGCSGVQVEEIWSLEAGQFEDL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663291</th>\n",
       "      <td>A0A6A4IYK5_40_294</td>\n",
       "      <td>MSYNDGNWCLIESDPGVFSELIREFGCSGVQVEEIWSLEAGQFEDL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663292</th>\n",
       "      <td>A0A6A4IYK5_40_295</td>\n",
       "      <td>MSYNDGNWCLIESDPGVFSELIREFGCSGVQVEEIWSLEAGQFEDL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663293</th>\n",
       "      <td>A0A6A4IYK5_40_296</td>\n",
       "      <td>MSYNDGNWCLIESDPGVFSELIREFGCSGVQVEEIWSLEAGQFEDL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1663294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                       sequence_str  \\\n",
       "0         A0A533UME0_40_-1  MKLSIAIPDSSVSDESTQLGKSMKISLIARACAIFRVQTVYIYHES...   \n",
       "1          A0A533UME0_40_0  XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXYIYHES...   \n",
       "2          A0A533UME0_40_1  MXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXIYHES...   \n",
       "3          A0A533UME0_40_2  MKXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXYHES...   \n",
       "4          A0A533UME0_40_3  MKLXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXHES...   \n",
       "...                    ...                                                ...   \n",
       "1663289  A0A6A4IYK5_40_292  MSYNDGNWCLIESDPGVFSELIREFGCSGVQVEEIWSLEAGQFEDL...   \n",
       "1663290  A0A6A4IYK5_40_293  MSYNDGNWCLIESDPGVFSELIREFGCSGVQVEEIWSLEAGQFEDL...   \n",
       "1663291  A0A6A4IYK5_40_294  MSYNDGNWCLIESDPGVFSELIREFGCSGVQVEEIWSLEAGQFEDL...   \n",
       "1663292  A0A6A4IYK5_40_295  MSYNDGNWCLIESDPGVFSELIREFGCSGVQVEEIWSLEAGQFEDL...   \n",
       "1663293  A0A6A4IYK5_40_296  MSYNDGNWCLIESDPGVFSELIREFGCSGVQVEEIWSLEAGQFEDL...   \n",
       "\n",
       "         label  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "...        ...  \n",
       "1663289      1  \n",
       "1663290      1  \n",
       "1663291      1  \n",
       "1663292      1  \n",
       "1663293      1  \n",
       "\n",
       "[1663294 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11c5bfd1-953e-4852-a7e7-3278901217a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /home/jovyan/my-conda-envs/eva_env/lib/python3.8/site-packages (0.19.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/jovyan/my-conda-envs/eva_env/lib/python3.8/site-packages (from scikit-image) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jovyan/my-conda-envs/eva_env/lib/python3.8/site-packages (from scikit-image) (22.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/jovyan/my-conda-envs/eva_env/lib/python3.8/site-packages (from scikit-image) (2022.10.10)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/jovyan/my-conda-envs/eva_env/lib/python3.8/site-packages (from scikit-image) (1.9.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/jovyan/my-conda-envs/eva_env/lib/python3.8/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/jovyan/my-conda-envs/eva_env/lib/python3.8/site-packages (from scikit-image) (9.4.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/jovyan/my-conda-envs/eva_env/lib/python3.8/site-packages (from scikit-image) (3.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/jovyan/my-conda-envs/eva_env/lib/python3.8/site-packages (from scikit-image) (2.24.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5cca23-3381-4b98-ad9e-f7e1d9682c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "import re\n",
    "import skimage.measure\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab8521d0-3914-46a9-9f7a-62693e1cde56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66402fcb-8a17-455d-87f2-abad7e5ab24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Run on GPU or CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82aacc2-70b1-46c7-bb5c-7901c2a4d3f2",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9720a57-b4e2-4591-88e9-1fe2ff445d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizerM2 = AutoTokenizer.from_pretrained(\"Rostlab/prot_bert_bfd\", do_lower_case=False)\n",
    "modelM2 = AutoModel.from_pretrained(\"Rostlab/prot_bert_bfd\")\n",
    "fe = pipeline('feature-extraction', model=modelM2, tokenizer=tokenizerM2, device=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d175a80f-597e-4cbc-933f-9301d235bd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence_str</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A533UME0_40_-1</td>\n",
       "      <td>M K L S I A I P D S S V S D E S T Q L G K S M ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A533UME0_40_0</td>\n",
       "      <td>X X X X X X X X X X X X X X X X X X X X X X X ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A533UME0_40_1</td>\n",
       "      <td>M X X X X X X X X X X X X X X X X X X X X X X ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A533UME0_40_2</td>\n",
       "      <td>M K X X X X X X X X X X X X X X X X X X X X X ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A533UME0_40_3</td>\n",
       "      <td>M K L X X X X X X X X X X X X X X X X X X X X ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663289</th>\n",
       "      <td>A0A6A4IYK5_40_292</td>\n",
       "      <td>M S Y N D G N W C L I E S D P G V F S E L I R ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663290</th>\n",
       "      <td>A0A6A4IYK5_40_293</td>\n",
       "      <td>M S Y N D G N W C L I E S D P G V F S E L I R ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663291</th>\n",
       "      <td>A0A6A4IYK5_40_294</td>\n",
       "      <td>M S Y N D G N W C L I E S D P G V F S E L I R ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663292</th>\n",
       "      <td>A0A6A4IYK5_40_295</td>\n",
       "      <td>M S Y N D G N W C L I E S D P G V F S E L I R ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663293</th>\n",
       "      <td>A0A6A4IYK5_40_296</td>\n",
       "      <td>M S Y N D G N W C L I E S D P G V F S E L I R ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1663294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                       sequence_str  \\\n",
       "0         A0A533UME0_40_-1  M K L S I A I P D S S V S D E S T Q L G K S M ...   \n",
       "1          A0A533UME0_40_0  X X X X X X X X X X X X X X X X X X X X X X X ...   \n",
       "2          A0A533UME0_40_1  M X X X X X X X X X X X X X X X X X X X X X X ...   \n",
       "3          A0A533UME0_40_2  M K X X X X X X X X X X X X X X X X X X X X X ...   \n",
       "4          A0A533UME0_40_3  M K L X X X X X X X X X X X X X X X X X X X X ...   \n",
       "...                    ...                                                ...   \n",
       "1663289  A0A6A4IYK5_40_292  M S Y N D G N W C L I E S D P G V F S E L I R ...   \n",
       "1663290  A0A6A4IYK5_40_293  M S Y N D G N W C L I E S D P G V F S E L I R ...   \n",
       "1663291  A0A6A4IYK5_40_294  M S Y N D G N W C L I E S D P G V F S E L I R ...   \n",
       "1663292  A0A6A4IYK5_40_295  M S Y N D G N W C L I E S D P G V F S E L I R ...   \n",
       "1663293  A0A6A4IYK5_40_296  M S Y N D G N W C L I E S D P G V F S E L I R ...   \n",
       "\n",
       "         label  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "...        ...  \n",
       "1663289      1  \n",
       "1663290      1  \n",
       "1663291      1  \n",
       "1663292      1  \n",
       "1663293      1  \n",
       "\n",
       "[1663294 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sequence_str'] = df['sequence_str'].apply(lambda sequence: ' '.join(re.sub(r'[UZOB]', 'X', sequence)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34fa1782-f2c7-4042-b890-8d8752fa656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with smaller amount of data:\n",
    "# df_tmp = df.loc[df['id'].str.contains('A0A533UME0_20')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f94569f-31d7-41f7-998c-2be4194c8472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(seq):\n",
    "    embedding = fe(seq)\n",
    "    features =  np.array(embedding[0][1:len(seq)+1])\n",
    "    features = skimage.measure.block_reduce(features, (1024, 1), np.average)\n",
    "    return np.array(features[0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e8bff3e-a645-4521-b54e-733eab677b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/1663294 [00:01<32:37:39, 14.16it/s]/home/jovyan/my-conda-envs/eva_env/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 45%|████▍     | 748427/1663294 [12:19:05<16:45:19, 15.17it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 47%|████▋     | 778211/1663294 [12:50:52<14:50:33, 16.56it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 47%|████▋     | 783552/1663294 [12:56:35<15:34:14, 15.69it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 49%|████▉     | 812906/1663294 [13:28:18<14:52:09, 15.89it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 49%|████▉     | 818167/1663294 [13:33:48<14:43:20, 15.95it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 51%|█████     | 847352/1663294 [14:05:01<13:42:14, 16.54it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 51%|█████▏    | 852683/1663294 [14:10:48<13:33:51, 16.60it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 53%|█████▎    | 879621/1663294 [14:39:08<14:01:21, 15.52it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 53%|█████▎    | 887173/1663294 [14:46:55<12:23:14, 17.40it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 55%|█████▍    | 913920/1663294 [15:13:55<12:04:50, 17.23it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 55%|█████▌    | 921064/1663294 [15:21:02<11:55:10, 17.30it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 57%|█████▋    | 947002/1663294 [15:47:28<12:11:27, 16.32it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 57%|█████▋    | 954256/1663294 [15:54:53<10:46:02, 18.29it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 59%|█████▉    | 980729/1663294 [16:21:50<10:20:52, 18.32it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 59%|█████▉    | 987646/1663294 [16:28:53<11:23:40, 16.47it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 61%|██████    | 1012122/1663294 [16:55:11<12:58:38, 13.94it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 61%|██████▏   | 1021363/1663294 [17:06:20<12:48:59, 13.91it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 63%|██████▎   | 1045376/1663294 [17:35:05<12:14:22, 14.02it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 63%|██████▎   | 1054694/1663294 [17:46:04<13:21:30, 12.66it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 65%|██████▍   | 1078655/1663294 [18:15:07<12:13:43, 13.28it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 65%|██████▌   | 1087928/1663294 [18:26:22<11:42:47, 13.64it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 67%|██████▋   | 1111795/1663294 [18:55:47<11:17:01, 13.58it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 76%|███████▋  | 1271904/1663294 [22:09:33<8:06:43, 13.40it/s] IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 1663294/1663294 [29:30:01<00:00, 15.66it/s]   \n"
     ]
    }
   ],
   "source": [
    "# df_tmp['features'] = df_tmp['sequence_str'].progress_apply(get_embedding)\n",
    "df['features'] = df['sequence_str'].progress_apply(get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630c7b1-8656-49fe-b096-d9f21b654dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b375023-8822-42ef-bdd1-d56211a62bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/my-conda-envs/eva_env/lib/python3.8/site-packages/huggingface_hub-0.11.1-py3.8.egg/huggingface_hub/utils/_deprecation.py:128: FutureWarning: 'set_access_token' (from 'huggingface_hub.hf_api') is deprecated and will be removed from version '0.14'. `HfApi.set_access_token` is deprecated as it is very ambiguous. Use `login` or `set_git_credential` instead.\n",
      "/home/jovyan/my-conda-envs/eva_env/lib/python3.8/site-packages/huggingface_hub-0.11.1-py3.8.egg/huggingface_hub/utils/_deprecation.py:128: FutureWarning: 'write_to_credential_store' (from 'huggingface_hub.utils._git_credential') is deprecated and will be removed from version '0.14'. Please use `huggingface_hub.set_git_credential` instead as it allows the user to chose which git-credential tool to use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ff804d8a164db4adbcdc6b53c45485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from huggingface_hub import HfApi, HfFolder\n",
    "\n",
    "# hf_dataset = Dataset.from_pandas(df_tmp)\n",
    "hf_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# set api for login and save token\n",
    "api=HfApi()\n",
    "api.set_access_token('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')\n",
    "\n",
    "hf_dataset.push_to_hub(HF_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a5ab8b-4e30-4be9-8c9c-f5dbd6e6d09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:eva_env]",
   "language": "python",
   "name": "conda-env-eva_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
